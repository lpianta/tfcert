{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Regression with TensorFlow\n",
    "\n",
    "Predicting a numerical variable based on some other combination of variables."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Import TensorFlow\n",
    "import tensorflow as tf\n",
    "tf.__version__"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating some data to view and fit"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create features\n",
    "X = np.array([-7.0, -4.0, -1.0, 2.0, 5.0, 8.0, 11.0, 14.0])\n",
    "\n",
    "# Create labels\n",
    "y = np.array([3.0, 6.0, 9.0, 12.0, 15.0, 18.0, 21.0, 24.0])\n",
    "\n",
    "# Visualiza it\n",
    "plt.scatter(X, y)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f5ae7b987f0>"
      ]
     },
     "metadata": {},
     "execution_count": 2
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# The relationship between X and y is y = X+10\n",
    "\n",
    "y == X+10\n",
    "\n",
    "# This is the function we want our neural network to learn"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Inputs and outputs shapes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Create a demo tensor for a mock housing price prediction problem\n",
    "house_info = tf.constant([\"bedroom\", \"bathroom\", \"garage\"])\n",
    "house_price = tf.constant([939700])\n",
    "house_info, house_price"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'bedroom', b'bathroom', b'garage'], dtype=object)>,\n",
       " <tf.Tensor: shape=(1,), dtype=int32, numpy=array([939700], dtype=int32)>)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# What is input and output shapes for our created X and y?\n",
    "# We want one feature to predict one label, so we take the [0] index.\n",
    "# We'll get empty shapes because we just have a list of scalars.\n",
    "input_shape = X[0].shape\n",
    "output_shape = y[0].shape\n",
    "input_shape, output_shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((), ())"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Turn our NumPy arrays into tensors with dtype float32\n",
    "X = tf.cast(tf.constant(X), dtype=tf.float32)\n",
    "y = tf.cast(tf.constant(y), dtype=tf.float32)\n",
    "X, y"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Steps in modelling with TensorFÃ²pw\n",
    "\n",
    "1. **Creating a model** - define the input and output layers, as well as the hidden layers.\n",
    "2. **Compiling a model** - define the loss function, the optimizer and evaluation metrics.\n",
    "3. **Fitting a model** - letting the model try to find patterns between X and y."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Set random seed for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model usin the Sequential API\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae, # mae = Mean Absolute Error\n",
    "              optimizer=tf.keras.optimizers.SGD(), # SGD = Stochastic Gradient Descent\n",
    "              metrics=[\"mae\"]\n",
    "             )\n",
    "\n",
    "# 3. Fit the model\n",
    "model.fit(X, y, epochs=5)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 707us/step - loss: 11.5048 - mae: 11.5048\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 647us/step - loss: 11.3723 - mae: 11.3723\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 589us/step - loss: 11.2398 - mae: 11.2398\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 820us/step - loss: 11.1073 - mae: 11.1073\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 653us/step - loss: 10.9748 - mae: 10.9748\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5adc0a1a30>"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Check X and y\n",
    "X, y"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Try and make a prediction using our model\n",
    "y_pred = model.predict([17.0])\n",
    "y_pred"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[12.716021]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Improving the model\n",
    "The model is far off, but we can have guessed it by looking at the loss and metric in the\n",
    "training phase.\n",
    "We can improve a model by altering any of the three steps we took to create it.\n",
    "1. **Creating a model** - here we can add more layers, increase the number of hidden units within each of the hidden layer, change the activation function of each layer.\n",
    "2. **Compiling a model** - here we can change the optimization function or the learning rate.\n",
    "3. **Fitting a model** - fit a model for more epochs or on more data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# Rebuild the model\n",
    "\n",
    "# 1. Create the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer=tf.keras.optimizers.SGD(),\n",
    "             metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model (this time we will train for longer)\n",
    "model.fit(X, y, epochs=100)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 667us/step - loss: 11.2219 - mae: 11.2219\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 943us/step - loss: 11.0894 - mae: 11.0894\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 730us/step - loss: 10.9569 - mae: 10.9569\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 679us/step - loss: 10.8244 - mae: 10.8244\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 708us/step - loss: 10.6919 - mae: 10.6919\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 661us/step - loss: 10.5594 - mae: 10.5594\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 842us/step - loss: 10.4269 - mae: 10.4269\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 848us/step - loss: 10.2944 - mae: 10.2944\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 703us/step - loss: 10.1619 - mae: 10.1619\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 901us/step - loss: 10.0294 - mae: 10.0294\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 857us/step - loss: 9.8969 - mae: 9.8969\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.7644 - mae: 9.7644\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 783us/step - loss: 9.6319 - mae: 9.6319\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 717us/step - loss: 9.4994 - mae: 9.4994\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 599us/step - loss: 9.3669 - mae: 9.3669\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 907us/step - loss: 9.2344 - mae: 9.2344\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 965us/step - loss: 9.1019 - mae: 9.1019\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 597us/step - loss: 8.9694 - mae: 8.9694\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.8369 - mae: 8.8369\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 687us/step - loss: 8.7044 - mae: 8.7044\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 712us/step - loss: 8.5719 - mae: 8.5719\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 753us/step - loss: 8.4394 - mae: 8.4394\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 780us/step - loss: 8.3069 - mae: 8.3069\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 778us/step - loss: 8.1744 - mae: 8.1744\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 648us/step - loss: 8.0419 - mae: 8.0419\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 909us/step - loss: 7.9094 - mae: 7.9094\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 826us/step - loss: 7.7769 - mae: 7.7769\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 604us/step - loss: 7.6444 - mae: 7.6444\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 805us/step - loss: 7.5119 - mae: 7.5119\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.3794 - mae: 7.3794\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 776us/step - loss: 7.2750 - mae: 7.2750\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 662us/step - loss: 7.2694 - mae: 7.2694\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 753us/step - loss: 7.2638 - mae: 7.2638\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 980us/step - loss: 7.2581 - mae: 7.2581\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.2525 - mae: 7.2525\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 7.2469 - mae: 7.2469\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 835us/step - loss: 7.2413 - mae: 7.2413\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 764us/step - loss: 7.2356 - mae: 7.2356\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 695us/step - loss: 7.2300 - mae: 7.2300\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 790us/step - loss: 7.2244 - mae: 7.2244\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 935us/step - loss: 7.2188 - mae: 7.2188\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 638us/step - loss: 7.2131 - mae: 7.2131\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 755us/step - loss: 7.2075 - mae: 7.2075\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 796us/step - loss: 7.2019 - mae: 7.2019\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 683us/step - loss: 7.1962 - mae: 7.1962\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.1906 - mae: 7.1906\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 732us/step - loss: 7.1850 - mae: 7.1850\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 669us/step - loss: 7.1794 - mae: 7.1794\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 887us/step - loss: 7.1737 - mae: 7.1737\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 911us/step - loss: 7.1681 - mae: 7.1681\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 748us/step - loss: 7.1625 - mae: 7.1625\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 798us/step - loss: 7.1569 - mae: 7.1569\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 981us/step - loss: 7.1512 - mae: 7.1512\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 661us/step - loss: 7.1456 - mae: 7.1456\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1400 - mae: 7.1400\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 833us/step - loss: 7.1344 - mae: 7.1344\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.1287 - mae: 7.1287\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 853us/step - loss: 7.1231 - mae: 7.1231\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.1175 - mae: 7.1175\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 977us/step - loss: 7.1119 - mae: 7.1119\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 782us/step - loss: 7.1062 - mae: 7.1062\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 860us/step - loss: 7.1006 - mae: 7.1006\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.0950 - mae: 7.0950\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 753us/step - loss: 7.0894 - mae: 7.0894\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 775us/step - loss: 7.0838 - mae: 7.0838\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 894us/step - loss: 7.0781 - mae: 7.0781\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 909us/step - loss: 7.0725 - mae: 7.0725\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 710us/step - loss: 7.0669 - mae: 7.0669\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 976us/step - loss: 7.0613 - mae: 7.0613\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.0556 - mae: 7.0556\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 887us/step - loss: 7.0500 - mae: 7.0500\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 808us/step - loss: 7.0444 - mae: 7.0444\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.0388 - mae: 7.0388\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 596us/step - loss: 7.0331 - mae: 7.0331\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 830us/step - loss: 7.0275 - mae: 7.0275\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 914us/step - loss: 7.0219 - mae: 7.0219\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 659us/step - loss: 7.0163 - mae: 7.0163\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 762us/step - loss: 7.0106 - mae: 7.0106\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.0050 - mae: 7.0050\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 991us/step - loss: 6.9994 - mae: 6.9994\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 662us/step - loss: 6.9938 - mae: 6.9938\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.9881 - mae: 6.9881\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 906us/step - loss: 6.9825 - mae: 6.9825\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.9769 - mae: 6.9769\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 945us/step - loss: 6.9713 - mae: 6.9713\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 722us/step - loss: 6.9656 - mae: 6.9656\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 895us/step - loss: 6.9600 - mae: 6.9600\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.9544 - mae: 6.9544\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 873us/step - loss: 6.9488 - mae: 6.9488\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.9431 - mae: 6.9431\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 835us/step - loss: 6.9375 - mae: 6.9375\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 888us/step - loss: 6.9319 - mae: 6.9319\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 901us/step - loss: 6.9262 - mae: 6.9262\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 822us/step - loss: 6.9206 - mae: 6.9206\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 689us/step - loss: 6.9150 - mae: 6.9150\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 657us/step - loss: 6.9094 - mae: 6.9094\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 663us/step - loss: 6.9038 - mae: 6.9038\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.8981 - mae: 6.8981\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 955us/step - loss: 6.8925 - mae: 6.8925\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.8869 - mae: 6.8869\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5ad00aec70>"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# Prediction should have improved (mae is now 6.8)\n",
    "model.predict([17.0])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[29.739855]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# Rebuild the model\n",
    "\n",
    "# 1. Create the model (this time adding a hidden layer with relu activation)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer=tf.keras.optimizers.SGD(),\n",
    "             metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "model.fit(X, y, epochs=100)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 667us/step - loss: 12.3193 - mae: 12.3193\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 652us/step - loss: 11.7804 - mae: 11.7804\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 670us/step - loss: 11.2324 - mae: 11.2324\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.6601 - mae: 10.6601\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 638us/step - loss: 10.0632 - mae: 10.0632\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 952us/step - loss: 9.4503 - mae: 9.4503\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 708us/step - loss: 8.7991 - mae: 8.7991\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 646us/step - loss: 8.1072 - mae: 8.1072\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 772us/step - loss: 7.3691 - mae: 7.3691\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 703us/step - loss: 6.5758 - mae: 6.5758\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 577us/step - loss: 5.7205 - mae: 5.7205\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.7947 - mae: 4.7947\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.3581 - mae: 4.3581\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 745us/step - loss: 4.3134 - mae: 4.3134\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 717us/step - loss: 4.2550 - mae: 4.2550\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 571us/step - loss: 4.2442 - mae: 4.2442\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 569us/step - loss: 4.1520 - mae: 4.1520\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 604us/step - loss: 4.1739 - mae: 4.1739\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 570us/step - loss: 4.0681 - mae: 4.0681\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 665us/step - loss: 4.0807 - mae: 4.0807\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 707us/step - loss: 3.9954 - mae: 3.9954\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 698us/step - loss: 3.9739 - mae: 3.9739\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 634us/step - loss: 3.9208 - mae: 3.9208\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 606us/step - loss: 3.9047 - mae: 3.9047\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 678us/step - loss: 3.9267 - mae: 3.9267\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 612us/step - loss: 3.8797 - mae: 3.8797\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 819us/step - loss: 3.9341 - mae: 3.9341\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 582us/step - loss: 3.8678 - mae: 3.8678\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 725us/step - loss: 3.9274 - mae: 3.9274\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 818us/step - loss: 3.8751 - mae: 3.8751\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 556us/step - loss: 3.9080 - mae: 3.9080\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 674us/step - loss: 3.8893 - mae: 3.8893\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 599us/step - loss: 3.8834 - mae: 3.8834\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 597us/step - loss: 3.8969 - mae: 3.8969\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 578us/step - loss: 3.8581 - mae: 3.8581\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 583us/step - loss: 3.9046 - mae: 3.9046\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8386 - mae: 3.8386\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 727us/step - loss: 3.9054 - mae: 3.9054\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 724us/step - loss: 3.8482 - mae: 3.8482\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 777us/step - loss: 3.8862 - mae: 3.8862\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 744us/step - loss: 3.8605 - mae: 3.8605\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 680us/step - loss: 3.8608 - mae: 3.8608\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 754us/step - loss: 3.8683 - mae: 3.8683\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 795us/step - loss: 3.8352 - mae: 3.8352\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 769us/step - loss: 3.8762 - mae: 3.8762\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 644us/step - loss: 3.8106 - mae: 3.8106\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 651us/step - loss: 3.8821 - mae: 3.8821\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 588us/step - loss: 3.8234 - mae: 3.8234\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 598us/step - loss: 3.8626 - mae: 3.8626\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 663us/step - loss: 3.8328 - mae: 3.8328\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 591us/step - loss: 3.8369 - mae: 3.8369\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 992us/step - loss: 3.8408 - mae: 3.8408\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 890us/step - loss: 3.8111 - mae: 3.8111\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8489 - mae: 3.8489\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 627us/step - loss: 3.7850 - mae: 3.7850\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 591us/step - loss: 3.8585 - mae: 3.8585\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 759us/step - loss: 3.7982 - mae: 3.7982\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.8377 - mae: 3.8377\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.8062 - mae: 3.8062\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 690us/step - loss: 3.8117 - mae: 3.8117\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.8144 - mae: 3.8144\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 674us/step - loss: 3.7856 - mae: 3.7856\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8227 - mae: 3.8227\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 593us/step - loss: 3.7593 - mae: 3.7593\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.8352 - mae: 3.8352\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 844us/step - loss: 3.7725 - mae: 3.7725\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 566us/step - loss: 3.8115 - mae: 3.8115\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 566us/step - loss: 3.7807 - mae: 3.7807\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7853 - mae: 3.7853\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 839us/step - loss: 3.7891 - mae: 3.7891\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 562us/step - loss: 3.7588 - mae: 3.7588\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 885us/step - loss: 3.7975 - mae: 3.7975\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 973us/step - loss: 3.7337 - mae: 3.7337\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 774us/step - loss: 3.8105 - mae: 3.8105\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7478 - mae: 3.7478\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 685us/step - loss: 3.7840 - mae: 3.7840\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 770us/step - loss: 3.7563 - mae: 3.7563\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 880us/step - loss: 3.7575 - mae: 3.7575\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7648 - mae: 3.7648\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7307 - mae: 3.7307\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 761us/step - loss: 3.7735 - mae: 3.7735\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 680us/step - loss: 3.7125 - mae: 3.7125\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 687us/step - loss: 3.7820 - mae: 3.7820\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 756us/step - loss: 3.7242 - mae: 3.7242\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 718us/step - loss: 3.7552 - mae: 3.7552\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7329 - mae: 3.7329\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 804us/step - loss: 3.7284 - mae: 3.7284\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 681us/step - loss: 3.7416 - mae: 3.7416\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 788us/step - loss: 3.7013 - mae: 3.7013\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7505 - mae: 3.7505\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 579us/step - loss: 3.6921 - mae: 3.6921\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 829us/step - loss: 3.7522 - mae: 3.7522\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 855us/step - loss: 3.7016 - mae: 3.7016\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 702us/step - loss: 3.7251 - mae: 3.7251\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 816us/step - loss: 3.7105 - mae: 3.7105\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.6979 - mae: 3.6979\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 671us/step - loss: 3.7194 - mae: 3.7194\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 856us/step - loss: 3.6705 - mae: 3.6705\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 885us/step - loss: 3.7299 - mae: 3.7299\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 802us/step - loss: 3.6711 - mae: 3.6711\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5a7079ca90>"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Prediction should be even better (mae is now around 3.5)\n",
    "model.predict([17.0])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[31.223137]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Seems like the previous model get closer to the actual result we want (27). Why?\n",
    "\n",
    "It can be that our model is overfitting, meaning is learning too well on the training data and it's not able to generalize well on new data.\n",
    "\n",
    "The metrics we see during training can not be representative of actual how well the model is working: the real evaluation comes from the prediction of data the model hasn't seen before.\n",
    "\n",
    "Tweaking the steps we changed before can help us avoid this problem (specially adjusting the learning rate of the optimizer)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluating a model\n",
    "In practice, a typical workflow is:\n",
    "\n",
    "Build a model -> fit it -> evaluate it -> tweak the model -> fit it -> evaluate it\n",
    "\n",
    "And repeat and repeat and repeat.\n",
    "\n",
    "When it comes to evaluation, visualization helps a lot.\n",
    "We can visualize:\n",
    "* The data- what data are we working with? what does it look like?\n",
    "* The model itself - what does our model look like?\n",
    "* The training of a model - how does a model perform while it learns?\n",
    "* The predictions - how the predictions line up against the ground truth?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# Make a bigger dataset\n",
    "X = tf.range(-100, 100, 4)\n",
    "X"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
       "        -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
       "        -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
       "         32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
       "         76,   80,   84,   88,   92,   96], dtype=int32)>"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# Make labels for the dataset\n",
    "y = X + 10\n",
    "y"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
       "       -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
       "        14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
       "        66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106], dtype=int32)>"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# Visualize the data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(X, y)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f5a706dddf0>"
      ]
     },
     "metadata": {},
     "execution_count": 16
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The three sets: train, validation, test\n",
    "\n",
    "* **Training set** - the model learns from this data. Typically 70-80% of the data.\n",
    "* **Validation set** - the model get tuned on this data. Typically 10-15% of the data.\n",
    "* **Test set** - the model gets evaluated on this data. Typically 10-15% of the data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# Check the length of how many samples we have\n",
    "len(X)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# Split the data into train and test sets\n",
    "X_train = X[:40] # first 40 are training samples (80% of the data)\n",
    "y_train = y[:40]\n",
    "\n",
    "X_test = X[40:] # last 10 are test samples (20% of the data)\n",
    "y_test = y[40:]\n",
    "\n",
    "len(X_train), len(y_train), len(X_test), len(y_test)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(40, 40, 10, 10)"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# Visualize the data splitted into train and test\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.scatter(X_train, y_train, c=\"b\", label=\"Training data\")\n",
    "plt.scatter(X_test, y_test, c=\"g\", label=\"Testing data\")\n",
    "plt.legend()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f5ad01aa490>"
      ]
     },
     "metadata": {},
     "execution_count": 19
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# 1. Create a model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer=tf.keras.optimizers.SGD(),\n",
    "             metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "# model.fit(X_train, y_train, epochs=100)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualize the model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-5f15418b3570>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[1;32m   1344\u001b[0m     \"\"\"\n\u001b[1;32m   1345\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1346\u001b[0;31m       raise ValueError('This model has not yet been built. '\n\u001b[0m\u001b[1;32m   1347\u001b[0m                        \u001b[0;34m'Build the model first by calling `build()` or calling '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1348\u001b[0m                        \u001b[0;34m'`fit()` with some data, or specify '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build."
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# Let's create a model that builds automatically by specifing the input shape argument\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model (same as above)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_shape=[1], name=\"input_layer\"),\n",
    "    tf.keras.layers.Dense(1, name=\"output_layer\")\n",
    "], name=\"A_model\")\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer=tf.keras.optimizers.SGD(),\n",
    "             metrics=[\"mae\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"A_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (Dense)          (None, 10)                20        \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* **Total Params** - the number of parameters in the model (patterns the model is going to learn)\n",
    "* **Trainable Params** - the parameters (patterns) the model can update as it trains.\n",
    "* **Non-trainable Params** - the parameters that aren't updated during training (typical when you bring in already learn patterns from other models during transfer learning)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "# Fit the model\n",
    "model.fit(X_train, y_train, epochs=100, verbose=0)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5a706b6fa0>"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualize our model's predictions\n",
    "\n",
    "To visualize prediction, we can plot them against the ground truth labels."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "# Make some prediction\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 70.55221 ],\n",
       "       [ 75.13992 ],\n",
       "       [ 79.72765 ],\n",
       "       [ 84.31538 ],\n",
       "       [ 88.9031  ],\n",
       "       [ 93.49082 ],\n",
       "       [ 98.07855 ],\n",
       "       [102.666275],\n",
       "       [107.254005],\n",
       "       [111.84173 ]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "# Plot(ting function to visualize predictions\n",
    "def plot_predictions(train_data=X_train, \n",
    "                    train_labels=y_train,\n",
    "                    test_data=X_test,\n",
    "                    test_labels=y_test,\n",
    "                    predictions=y_pred):\n",
    "    \"\"\"\n",
    "    Plots training data, test data and compares predictions to ground truth labels.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10,7))\n",
    "    # Plot training data in blue\n",
    "    plt.scatter(train_data, train_labels, c=\"b\", label=\"Training data\")\n",
    "    # Plot testing data in green\n",
    "    plt.scatter(test_data, test_labels, c=\"g\", label=\"Testing data\")\n",
    "    # Plot model's prediction in red\n",
    "    plt.scatter(test_data, predictions, c=\"r\", label=\"Predictions\")\n",
    "    # Show the lenged\n",
    "    plt.legend()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "plot_predictions()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluating our model's predictions with regression evaluation metrics\n",
    "\n",
    "Depending on the problem you're working on there will be diferent evaluation metrics to evaluate your model's performance.\n",
    "\n",
    "For regression problem there are two main metrics:\n",
    "* MAE - Mean Average Error\n",
    "* MSE - Mean Squared Error"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "# Evaluate the model on the test set\n",
    "model.evaluate(X_test, y_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1/1 [==============================] - 0s 680us/step - loss: 3.1970 - mae: 3.1970\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[3.1969642639160156, 3.1969642639160156]"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "# Calculate the mean absolute error (MAE)\n",
    "mae = tf.metrics.mean_absolute_error(y_test, tf.constant(y_pred))\n",
    "mae"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([17.558233, 14.116046, 11.708939, 10.336925, 10.      , 10.698164,\n",
       "       12.447131, 15.33302 , 19.254005, 23.841728], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "# Why it's giving this strange output? Check the dimensions of the two tensors\n",
    "tf.shape(y_test), tf.shape(tf.constant(y_pred))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1,), dtype=int32, numpy=array([10], dtype=int32)>,\n",
       " <tf.Tensor: shape=(2,), dtype=int32, numpy=array([10,  1], dtype=int32)>)"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "# y_pred has an extra dimension! We can remove that using the squeeze method\n",
    "tf.squeeze(y_pred)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([ 70.55221 ,  75.13992 ,  79.72765 ,  84.31538 ,  88.9031  ,\n",
       "        93.49082 ,  98.07855 , 102.666275, 107.254005, 111.84173 ],\n",
       "      dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "# Calculate the mean absolute error again\n",
    "mae = tf.metrics.mean_absolute_error(y_test, tf.squeeze(y_pred))\n",
    "mae"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=3.1969643>"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "# Calculate the mean squared error\n",
    "mse = tf.metrics.mean_squared_error(y_test, tf.squeeze(y_pred))\n",
    "mse"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=13.0703>"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "# Functions to reuse MAE and MSE\n",
    "def mae(y_true, y_pred):\n",
    "    return tf.metrics.mean_absolute_error(y_true, tf.squeeze(y_pred))\n",
    "\n",
    "def mse(y_true, y_pred):\n",
    "    return tf.metrics.mean_squared_error(y_true, tf.squeeze(y_pred))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Run experiments to imporve our model\n",
    "\n",
    "1. Get more data - get more examples for the model to train on.\n",
    "2. Make the model larger - using a more complex model (more layers, more hidden units)\n",
    "3. Train for longer - give your model more of a chance to find patterns in the data\n",
    "\n",
    "Let's do three modelling experiments:\n",
    "1. `model_1` - 1 layer trained for 100 epochs\n",
    "2. `model_2` - 2 layers trained for 100 epochs\n",
    "3. `model_3` - 2 layers trained for 500 epochs\n",
    "\n",
    "We tweak a parameter at a time."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Build model_1**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "model_1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)])\n",
    "\n",
    "# 2. Compile the model\n",
    "model_1.compile(loss=tf.keras.losses.mae,\n",
    "                optimizer=tf.keras.optimizers.SGD(),\n",
    "                metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "model_1.fit(X_train, y_train, epochs=100)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 15.9024 - mae: 15.9024\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 834us/step - loss: 11.2837 - mae: 11.2837\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 865us/step - loss: 11.1074 - mae: 11.1074\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 934us/step - loss: 9.2990 - mae: 9.2990\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 865us/step - loss: 10.1677 - mae: 10.1677\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 940us/step - loss: 9.4303 - mae: 9.4303\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 8.5704 - mae: 8.5704\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 765us/step - loss: 9.0442 - mae: 9.0442\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 777us/step - loss: 18.7517 - mae: 18.7517\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 864us/step - loss: 10.1142 - mae: 10.1142\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.3980 - mae: 8.3980\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 839us/step - loss: 10.6639 - mae: 10.6639\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 714us/step - loss: 9.7977 - mae: 9.7977\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 840us/step - loss: 16.0103 - mae: 16.0103\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 830us/step - loss: 11.4068 - mae: 11.4068\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 817us/step - loss: 8.5393 - mae: 8.5393\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 13.6348 - mae: 13.6348\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 882us/step - loss: 11.4629 - mae: 11.4629\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 856us/step - loss: 17.9148 - mae: 17.9148\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 769us/step - loss: 15.0494 - mae: 15.0494\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 837us/step - loss: 11.0216 - mae: 11.0216\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 983us/step - loss: 8.1558 - mae: 8.1558\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 928us/step - loss: 9.5138 - mae: 9.5138\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 999us/step - loss: 7.6617 - mae: 7.6617\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 793us/step - loss: 13.1859 - mae: 13.1859\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 16.4211 - mae: 16.4211\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 771us/step - loss: 13.1659 - mae: 13.1659\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 782us/step - loss: 14.2559 - mae: 14.2559\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 888us/step - loss: 10.0670 - mae: 10.0670\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 818us/step - loss: 16.3409 - mae: 16.3409\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 990us/step - loss: 23.6444 - mae: 23.6444\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 876us/step - loss: 7.6215 - mae: 7.6215\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 820us/step - loss: 9.3221 - mae: 9.3221\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 852us/step - loss: 13.7313 - mae: 13.7313\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 866us/step - loss: 11.1276 - mae: 11.1276\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 980us/step - loss: 13.3222 - mae: 13.3222\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 800us/step - loss: 9.4763 - mae: 9.4763\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.1381 - mae: 10.1381\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 886us/step - loss: 10.1793 - mae: 10.1793\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 924us/step - loss: 10.9137 - mae: 10.9137\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 767us/step - loss: 7.9063 - mae: 7.9063\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 10.0914 - mae: 10.0914\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 824us/step - loss: 8.7006 - mae: 8.7006\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.2047 - mae: 12.2047\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 920us/step - loss: 13.7970 - mae: 13.7970\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 858us/step - loss: 8.4687 - mae: 8.4687\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 942us/step - loss: 9.1330 - mae: 9.1330\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.6190 - mae: 10.6190\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.7503 - mae: 7.7503\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 802us/step - loss: 9.5407 - mae: 9.5407\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.1584 - mae: 9.1584\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 16.3630 - mae: 16.3630\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 905us/step - loss: 14.1299 - mae: 14.1299\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 21.1247 - mae: 21.1247\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 16.3961 - mae: 16.3961\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.9806 - mae: 9.9806\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 886us/step - loss: 9.9606 - mae: 9.9606\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.2209 - mae: 9.2209\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 786us/step - loss: 8.4239 - mae: 8.4239\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.4869 - mae: 9.4869\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.4355 - mae: 11.4355\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.6887 - mae: 11.6887\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.0838 - mae: 7.0838\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 16.9675 - mae: 16.9675\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.4599 - mae: 12.4599\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.0184 - mae: 13.0184\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.0600 - mae: 8.0600\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 933us/step - loss: 10.1888 - mae: 10.1888\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.3633 - mae: 12.3633\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.0516 - mae: 9.0516\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 855us/step - loss: 10.0378 - mae: 10.0378\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.0516 - mae: 10.0516\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.6151 - mae: 12.6151\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.3819 - mae: 10.3819\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 968us/step - loss: 9.7229 - mae: 9.7229\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.2252 - mae: 11.2252\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.3642 - mae: 8.3642\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 960us/step - loss: 9.1274 - mae: 9.1274\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 862us/step - loss: 19.5039 - mae: 19.5039\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 14.8945 - mae: 14.8945\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.0034 - mae: 9.0034\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 807us/step - loss: 13.0206 - mae: 13.0206\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.9299 - mae: 7.9299\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.6872 - mae: 7.6872\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.0328 - mae: 10.0328\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.2433 - mae: 9.2433\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.0209 - mae: 12.0209\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.6389 - mae: 10.6389\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.2667 - mae: 7.2667\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.7786 - mae: 12.7786\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.3481 - mae: 7.3481\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.7175 - mae: 7.7175\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 864us/step - loss: 7.1263 - mae: 7.1263\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 952us/step - loss: 12.6190 - mae: 12.6190\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.0912 - mae: 10.0912\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 892us/step - loss: 9.3558 - mae: 9.3558\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.6834 - mae: 12.6834\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 863us/step - loss: 8.6762 - mae: 8.6762\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.4693 - mae: 9.4693\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 873us/step - loss: 8.7067 - mae: 8.7067\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5a7045ac10>"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "# Make and plot predictions for model_1\n",
    "y_preds_1 = model_1.predict(X_test)\n",
    "plot_predictions(predictions=y_preds_1)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "# Calculate model_1 evaluation metrics\n",
    "mae_1 = mae(y_test, y_preds_1)\n",
    "mse_1 = mse(y_test, y_preds_1)\n",
    "mae_1, mse_1"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=18.745327>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=353.5734>)"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Build `model_2`**\n",
    "* 2 dense layers, trained for 100 epochs"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Build the model\n",
    "model_2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model_2.compile(loss=tf.keras.losses.mae,\n",
    "                optimizer=tf.keras.optimizers.SGD(),\n",
    "                metrics=[\"mse\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "model_2.fit(X_train, y_train, epochs=100)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 27.4058 - mse: 1084.1482\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 884us/step - loss: 24.6339 - mse: 777.9203\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 894us/step - loss: 29.8935 - mse: 1334.8951\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 896us/step - loss: 27.4055 - mse: 1106.8038\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 914us/step - loss: 14.9463 - mse: 281.1077\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 987us/step - loss: 11.8819 - mse: 168.6622\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 820us/step - loss: 11.1988 - mse: 151.3509\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.0910 - mse: 160.3746\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 956us/step - loss: 40.4763 - mse: 2586.0093\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 27.8688 - mse: 1094.4385\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 10.2473 - mse: 147.9359\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 907us/step - loss: 25.2803 - mse: 890.3866\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 827us/step - loss: 16.9897 - mse: 399.9678\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 876us/step - loss: 25.9217 - mse: 1049.5519\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 834us/step - loss: 17.9948 - mse: 450.2584\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 906us/step - loss: 7.3510 - mse: 80.6206\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 886us/step - loss: 10.8636 - mse: 174.7868\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 850us/step - loss: 19.5304 - mse: 565.8051\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 883us/step - loss: 10.3469 - mse: 167.7749\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 858us/step - loss: 17.6985 - mse: 455.7094\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 955us/step - loss: 15.8984 - mse: 347.1928\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 915us/step - loss: 14.1991 - mse: 285.1766\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.7720 - mse: 91.7852\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.0570 - mse: 153.7430\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 808us/step - loss: 12.6838 - mse: 233.2951\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 980us/step - loss: 26.1877 - mse: 1024.6094\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 872us/step - loss: 11.7432 - mse: 194.8453\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 857us/step - loss: 22.8730 - mse: 835.6071\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 811us/step - loss: 9.2459 - mse: 96.7787\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 893us/step - loss: 29.2641 - mse: 1535.1339\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 914us/step - loss: 53.0224 - mse: 5030.2949\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 802us/step - loss: 11.9951 - mse: 211.7024\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 924us/step - loss: 15.6357 - mse: 337.3665\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 840us/step - loss: 12.6925 - mse: 214.4822\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 795us/step - loss: 9.2398 - mse: 92.9126\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 880us/step - loss: 16.6497 - mse: 403.6570\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 888us/step - loss: 11.0382 - mse: 192.3919\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 821us/step - loss: 18.1634 - mse: 433.6719\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 955us/step - loss: 19.1013 - mse: 529.6442\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 869us/step - loss: 20.4324 - mse: 610.1326\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 900us/step - loss: 14.9102 - mse: 279.6181\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 818us/step - loss: 12.2809 - mse: 186.6178\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 953us/step - loss: 10.7333 - mse: 167.0951\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 994us/step - loss: 23.0260 - mse: 830.4240\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.3897 - mse: 128.9549\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 894us/step - loss: 11.7904 - mse: 181.9211\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 865us/step - loss: 9.6438 - mse: 153.8708\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 17.2335 - mse: 402.8495\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 897us/step - loss: 9.5729 - mse: 99.8336\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 844us/step - loss: 13.8185 - mse: 260.3670\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 978us/step - loss: 11.5958 - mse: 154.7956\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 30.5538 - mse: 1613.0880\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 764us/step - loss: 14.3541 - mse: 302.5292\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 990us/step - loss: 23.9713 - mse: 859.3983\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 23.1938 - mse: 805.5450\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.8837 - mse: 170.9834\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.7445 - mse: 198.7016\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 809us/step - loss: 9.5995 - mse: 102.5890\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 976us/step - loss: 12.5172 - mse: 216.3369\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 996us/step - loss: 12.3200 - mse: 208.6371\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 17.4604 - mse: 428.6395\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.6052 - mse: 136.9777\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 940us/step - loss: 10.4893 - mse: 152.4555\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 985us/step - loss: 24.8450 - mse: 911.7513\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.6761 - mse: 142.7375\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 929us/step - loss: 21.7810 - mse: 704.4494\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 995us/step - loss: 10.7136 - mse: 136.0195\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.6397 - mse: 149.2301\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 22.6914 - mse: 742.1767\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.3316 - mse: 166.1628\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 944us/step - loss: 15.4355 - mse: 323.0842\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 6.7437 - mse: 67.0209\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 854us/step - loss: 11.6891 - mse: 183.7296\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 877us/step - loss: 24.0400 - mse: 908.8998\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 867us/step - loss: 9.5897 - mse: 149.3948\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 12.4371 - mse: 188.3310\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 888us/step - loss: 16.6489 - mse: 429.2708\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.0614 - mse: 95.4870\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 23.9675 - mse: 864.0865\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 978us/step - loss: 26.7463 - mse: 1104.4033\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 973us/step - loss: 11.6714 - mse: 170.7056\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 847us/step - loss: 12.0228 - mse: 211.9191\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 17.4218 - mse: 395.5588\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.2629 - mse: 73.0935\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 933us/step - loss: 14.9650 - mse: 312.8360\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 822us/step - loss: 15.2862 - mse: 315.3605\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 19.1086 - mse: 521.2532\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 29.8229 - mse: 1287.1917\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 977us/step - loss: 10.1742 - mse: 124.1342\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 828us/step - loss: 21.5240 - mse: 663.8616\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.5716 - mse: 161.7467\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 18.3977 - mse: 464.1330\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.4138 - mse: 81.9820\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 17.7380 - mse: 445.7383\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 877us/step - loss: 11.1144 - mse: 164.0822\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 19.4346 - mse: 510.5847\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.1593 - mse: 209.9758\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.5653 - mse: 169.4053\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 13.8827 - mse: 265.4632\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 969us/step - loss: 20.2277 - mse: 608.8224\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5a70310eb0>"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "# Make and plot predictions of model_2\n",
    "y_preds_2 = model_2.predict(X_test)\n",
    "plot_predictions(predictions=y_preds_2)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "# Calculate model_2 evaluation metrics\n",
    "mae_2 = mae(y_test, y_preds_2)\n",
    "mse_2 = mse(y_test, y_preds_2)\n",
    "mae_2, mse_2"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=3.1969643>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=13.0703>)"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Build `model_3`**\n",
    "* Two layers trained for 500 epochs"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Build the model\n",
    "model_3 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model_3.compile(loss=tf.keras.losses.mae,\n",
    "                optimizer=tf.keras.optimizers.SGD(),\n",
    "                metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "model_3.fit(X_train, y_train, epochs=500)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/500\n",
      "2/2 [==============================] - 0s 810us/step - loss: 27.4058 - mae: 27.4058\n",
      "Epoch 2/500\n",
      "2/2 [==============================] - 0s 901us/step - loss: 24.6339 - mae: 24.6339\n",
      "Epoch 3/500\n",
      "2/2 [==============================] - 0s 826us/step - loss: 29.8935 - mae: 29.8935\n",
      "Epoch 4/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 27.4055 - mae: 27.4055\n",
      "Epoch 5/500\n",
      "2/2 [==============================] - 0s 818us/step - loss: 14.9463 - mae: 14.9463\n",
      "Epoch 6/500\n",
      "2/2 [==============================] - 0s 945us/step - loss: 11.8819 - mae: 11.8819\n",
      "Epoch 7/500\n",
      "2/2 [==============================] - 0s 938us/step - loss: 11.1988 - mae: 11.1988\n",
      "Epoch 8/500\n",
      "2/2 [==============================] - 0s 892us/step - loss: 11.0910 - mae: 11.0910\n",
      "Epoch 9/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 40.4763 - mae: 40.4763\n",
      "Epoch 10/500\n",
      "2/2 [==============================] - 0s 855us/step - loss: 27.8688 - mae: 27.8688\n",
      "Epoch 11/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.2473 - mae: 10.2473\n",
      "Epoch 12/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 25.2803 - mae: 25.2803\n",
      "Epoch 13/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 16.9897 - mae: 16.9897\n",
      "Epoch 14/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 25.9217 - mae: 25.9217\n",
      "Epoch 15/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 17.9948 - mae: 17.9948\n",
      "Epoch 16/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.3510 - mae: 7.3510\n",
      "Epoch 17/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.8636 - mae: 10.8636\n",
      "Epoch 18/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 19.5304 - mae: 19.5304\n",
      "Epoch 19/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.3469 - mae: 10.3469\n",
      "Epoch 20/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 17.6985 - mae: 17.6985\n",
      "Epoch 21/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 15.8984 - mae: 15.8984\n",
      "Epoch 22/500\n",
      "2/2 [==============================] - 0s 863us/step - loss: 14.1991 - mae: 14.1991\n",
      "Epoch 23/500\n",
      "2/2 [==============================] - 0s 987us/step - loss: 8.7720 - mae: 8.7720\n",
      "Epoch 24/500\n",
      "2/2 [==============================] - 0s 818us/step - loss: 11.0570 - mae: 11.0570\n",
      "Epoch 25/500\n",
      "2/2 [==============================] - 0s 837us/step - loss: 12.6838 - mae: 12.6838\n",
      "Epoch 26/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 26.1877 - mae: 26.1877\n",
      "Epoch 27/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.7432 - mae: 11.7432\n",
      "Epoch 28/500\n",
      "2/2 [==============================] - 0s 945us/step - loss: 22.8730 - mae: 22.8730\n",
      "Epoch 29/500\n",
      "2/2 [==============================] - 0s 867us/step - loss: 9.2459 - mae: 9.2459\n",
      "Epoch 30/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 29.2641 - mae: 29.2641\n",
      "Epoch 31/500\n",
      "2/2 [==============================] - 0s 838us/step - loss: 53.0224 - mae: 53.0224\n",
      "Epoch 32/500\n",
      "2/2 [==============================] - 0s 834us/step - loss: 11.9951 - mae: 11.9951\n",
      "Epoch 33/500\n",
      "2/2 [==============================] - 0s 868us/step - loss: 15.6357 - mae: 15.6357\n",
      "Epoch 34/500\n",
      "2/2 [==============================] - 0s 889us/step - loss: 12.6925 - mae: 12.6925\n",
      "Epoch 35/500\n",
      "2/2 [==============================] - 0s 860us/step - loss: 9.2398 - mae: 9.2398\n",
      "Epoch 36/500\n",
      "2/2 [==============================] - 0s 785us/step - loss: 16.6497 - mae: 16.6497\n",
      "Epoch 37/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.0382 - mae: 11.0382\n",
      "Epoch 38/500\n",
      "2/2 [==============================] - 0s 933us/step - loss: 18.1634 - mae: 18.1634\n",
      "Epoch 39/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 19.1013 - mae: 19.1013\n",
      "Epoch 40/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 20.4324 - mae: 20.4324\n",
      "Epoch 41/500\n",
      "2/2 [==============================] - 0s 904us/step - loss: 14.9102 - mae: 14.9102\n",
      "Epoch 42/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.2809 - mae: 12.2809\n",
      "Epoch 43/500\n",
      "2/2 [==============================] - 0s 914us/step - loss: 10.7333 - mae: 10.7333\n",
      "Epoch 44/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 23.0260 - mae: 23.0260\n",
      "Epoch 45/500\n",
      "2/2 [==============================] - 0s 913us/step - loss: 10.3897 - mae: 10.3897\n",
      "Epoch 46/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.7904 - mae: 11.7904\n",
      "Epoch 47/500\n",
      "2/2 [==============================] - 0s 871us/step - loss: 9.6438 - mae: 9.6438\n",
      "Epoch 48/500\n",
      "2/2 [==============================] - 0s 950us/step - loss: 17.2335 - mae: 17.2335\n",
      "Epoch 49/500\n",
      "2/2 [==============================] - 0s 943us/step - loss: 9.5729 - mae: 9.5729\n",
      "Epoch 50/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 13.8185 - mae: 13.8185\n",
      "Epoch 51/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.5958 - mae: 11.5958\n",
      "Epoch 52/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 30.5538 - mae: 30.5538\n",
      "Epoch 53/500\n",
      "2/2 [==============================] - 0s 911us/step - loss: 14.3541 - mae: 14.3541\n",
      "Epoch 54/500\n",
      "2/2 [==============================] - 0s 850us/step - loss: 23.9713 - mae: 23.9713\n",
      "Epoch 55/500\n",
      "2/2 [==============================] - 0s 954us/step - loss: 23.1938 - mae: 23.1938\n",
      "Epoch 56/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.8837 - mae: 10.8837\n",
      "Epoch 57/500\n",
      "2/2 [==============================] - 0s 882us/step - loss: 12.7445 - mae: 12.7445\n",
      "Epoch 58/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.5995 - mae: 9.5995\n",
      "Epoch 59/500\n",
      "2/2 [==============================] - 0s 989us/step - loss: 12.5172 - mae: 12.5172\n",
      "Epoch 60/500\n",
      "2/2 [==============================] - 0s 989us/step - loss: 12.3200 - mae: 12.3200\n",
      "Epoch 61/500\n",
      "2/2 [==============================] - 0s 868us/step - loss: 17.4604 - mae: 17.4604\n",
      "Epoch 62/500\n",
      "2/2 [==============================] - 0s 901us/step - loss: 10.6052 - mae: 10.6052\n",
      "Epoch 63/500\n",
      "2/2 [==============================] - 0s 861us/step - loss: 10.4893 - mae: 10.4893\n",
      "Epoch 64/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 24.8450 - mae: 24.8450\n",
      "Epoch 65/500\n",
      "2/2 [==============================] - 0s 967us/step - loss: 10.6761 - mae: 10.6761\n",
      "Epoch 66/500\n",
      "2/2 [==============================] - 0s 767us/step - loss: 21.7810 - mae: 21.7810\n",
      "Epoch 67/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.7136 - mae: 10.7136\n",
      "Epoch 68/500\n",
      "2/2 [==============================] - 0s 776us/step - loss: 10.6397 - mae: 10.6397\n",
      "Epoch 69/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 22.6914 - mae: 22.6914\n",
      "Epoch 70/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.3316 - mae: 9.3316\n",
      "Epoch 71/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 15.4355 - mae: 15.4355\n",
      "Epoch 72/500\n",
      "2/2 [==============================] - 0s 796us/step - loss: 6.7437 - mae: 6.7437\n",
      "Epoch 73/500\n",
      "2/2 [==============================] - 0s 776us/step - loss: 11.6891 - mae: 11.6891\n",
      "Epoch 74/500\n",
      "2/2 [==============================] - 0s 860us/step - loss: 24.0400 - mae: 24.0400\n",
      "Epoch 75/500\n",
      "2/2 [==============================] - 0s 925us/step - loss: 9.5897 - mae: 9.5897\n",
      "Epoch 76/500\n",
      "2/2 [==============================] - 0s 833us/step - loss: 12.4371 - mae: 12.4371\n",
      "Epoch 77/500\n",
      "2/2 [==============================] - 0s 966us/step - loss: 16.6489 - mae: 16.6489\n",
      "Epoch 78/500\n",
      "2/2 [==============================] - 0s 785us/step - loss: 9.0614 - mae: 9.0614\n",
      "Epoch 79/500\n",
      "2/2 [==============================] - 0s 958us/step - loss: 23.9675 - mae: 23.9675\n",
      "Epoch 80/500\n",
      "2/2 [==============================] - 0s 918us/step - loss: 26.7463 - mae: 26.7463\n",
      "Epoch 81/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.6714 - mae: 11.6714\n",
      "Epoch 82/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.0228 - mae: 12.0228\n",
      "Epoch 83/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 17.4218 - mae: 17.4218\n",
      "Epoch 84/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.2629 - mae: 7.2629\n",
      "Epoch 85/500\n",
      "2/2 [==============================] - 0s 968us/step - loss: 14.9650 - mae: 14.9650\n",
      "Epoch 86/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 15.2862 - mae: 15.2862\n",
      "Epoch 87/500\n",
      "2/2 [==============================] - 0s 857us/step - loss: 19.1086 - mae: 19.1086\n",
      "Epoch 88/500\n",
      "2/2 [==============================] - 0s 950us/step - loss: 29.8229 - mae: 29.8229\n",
      "Epoch 89/500\n",
      "2/2 [==============================] - 0s 747us/step - loss: 10.1742 - mae: 10.1742\n",
      "Epoch 90/500\n",
      "2/2 [==============================] - 0s 863us/step - loss: 21.5240 - mae: 21.5240\n",
      "Epoch 91/500\n",
      "2/2 [==============================] - 0s 810us/step - loss: 10.5716 - mae: 10.5716\n",
      "Epoch 92/500\n",
      "2/2 [==============================] - 0s 870us/step - loss: 18.3977 - mae: 18.3977\n",
      "Epoch 93/500\n",
      "2/2 [==============================] - 0s 824us/step - loss: 7.4138 - mae: 7.4138\n",
      "Epoch 94/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 17.7380 - mae: 17.7380\n",
      "Epoch 95/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.1144 - mae: 11.1144\n",
      "Epoch 96/500\n",
      "2/2 [==============================] - 0s 960us/step - loss: 19.4346 - mae: 19.4346\n",
      "Epoch 97/500\n",
      "2/2 [==============================] - 0s 791us/step - loss: 12.1593 - mae: 12.1593\n",
      "Epoch 98/500\n",
      "2/2 [==============================] - 0s 832us/step - loss: 11.5653 - mae: 11.5653\n",
      "Epoch 99/500\n",
      "2/2 [==============================] - 0s 821us/step - loss: 13.8827 - mae: 13.8827\n",
      "Epoch 100/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 20.2277 - mae: 20.2277\n",
      "Epoch 101/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.4479 - mae: 11.4479\n",
      "Epoch 102/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 17.4842 - mae: 17.4842\n",
      "Epoch 103/500\n",
      "2/2 [==============================] - 0s 782us/step - loss: 7.0217 - mae: 7.0217\n",
      "Epoch 104/500\n",
      "2/2 [==============================] - 0s 831us/step - loss: 23.5789 - mae: 23.5789\n",
      "Epoch 105/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 16.8932 - mae: 16.8932\n",
      "Epoch 106/500\n",
      "2/2 [==============================] - 0s 783us/step - loss: 9.2954 - mae: 9.2954\n",
      "Epoch 107/500\n",
      "2/2 [==============================] - 0s 791us/step - loss: 25.3749 - mae: 25.3749\n",
      "Epoch 108/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 13.4621 - mae: 13.4621\n",
      "Epoch 109/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.5238 - mae: 9.5238\n",
      "Epoch 110/500\n",
      "2/2 [==============================] - 0s 952us/step - loss: 9.6722 - mae: 9.6722\n",
      "Epoch 111/500\n",
      "2/2 [==============================] - 0s 944us/step - loss: 14.5987 - mae: 14.5987\n",
      "Epoch 112/500\n",
      "2/2 [==============================] - 0s 945us/step - loss: 9.5670 - mae: 9.5670\n",
      "Epoch 113/500\n",
      "2/2 [==============================] - 0s 881us/step - loss: 17.8093 - mae: 17.8093\n",
      "Epoch 114/500\n",
      "2/2 [==============================] - 0s 858us/step - loss: 17.1782 - mae: 17.1782\n",
      "Epoch 115/500\n",
      "2/2 [==============================] - 0s 925us/step - loss: 11.1182 - mae: 11.1182\n",
      "Epoch 116/500\n",
      "2/2 [==============================] - 0s 860us/step - loss: 23.3071 - mae: 23.3071\n",
      "Epoch 117/500\n",
      "2/2 [==============================] - 0s 860us/step - loss: 9.6144 - mae: 9.6144\n",
      "Epoch 118/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.6899 - mae: 10.6899\n",
      "Epoch 119/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.0355 - mae: 8.0355\n",
      "Epoch 120/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 29.6859 - mae: 29.6859\n",
      "Epoch 121/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.0714 - mae: 8.0714\n",
      "Epoch 122/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 28.3087 - mae: 28.3087\n",
      "Epoch 123/500\n",
      "2/2 [==============================] - 0s 806us/step - loss: 32.9014 - mae: 32.9014\n",
      "Epoch 124/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 19.6291 - mae: 19.6291\n",
      "Epoch 125/500\n",
      "2/2 [==============================] - 0s 941us/step - loss: 7.0095 - mae: 7.0095\n",
      "Epoch 126/500\n",
      "2/2 [==============================] - 0s 935us/step - loss: 21.8056 - mae: 21.8056\n",
      "Epoch 127/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.9812 - mae: 7.9812\n",
      "Epoch 128/500\n",
      "2/2 [==============================] - 0s 985us/step - loss: 21.0585 - mae: 21.0585\n",
      "Epoch 129/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.0107 - mae: 9.0107\n",
      "Epoch 130/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 24.0502 - mae: 24.0502\n",
      "Epoch 131/500\n",
      "2/2 [==============================] - 0s 836us/step - loss: 9.7537 - mae: 9.7537\n",
      "Epoch 132/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 18.3052 - mae: 18.3052\n",
      "Epoch 133/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.5833 - mae: 7.5833\n",
      "Epoch 134/500\n",
      "2/2 [==============================] - 0s 922us/step - loss: 18.5755 - mae: 18.5755\n",
      "Epoch 135/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.5360 - mae: 10.5360\n",
      "Epoch 136/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 18.2694 - mae: 18.2694\n",
      "Epoch 137/500\n",
      "2/2 [==============================] - 0s 823us/step - loss: 23.1658 - mae: 23.1658\n",
      "Epoch 138/500\n",
      "2/2 [==============================] - 0s 932us/step - loss: 9.1362 - mae: 9.1362\n",
      "Epoch 139/500\n",
      "2/2 [==============================] - 0s 933us/step - loss: 8.9181 - mae: 8.9181\n",
      "Epoch 140/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 16.4732 - mae: 16.4732\n",
      "Epoch 141/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.4208 - mae: 8.4208\n",
      "Epoch 142/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 36.9540 - mae: 36.9540\n",
      "Epoch 143/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 25.5820 - mae: 25.5820\n",
      "Epoch 144/500\n",
      "2/2 [==============================] - 0s 795us/step - loss: 9.5392 - mae: 9.5392\n",
      "Epoch 145/500\n",
      "2/2 [==============================] - 0s 968us/step - loss: 26.6058 - mae: 26.6058\n",
      "Epoch 146/500\n",
      "2/2 [==============================] - 0s 822us/step - loss: 8.7248 - mae: 8.7248\n",
      "Epoch 147/500\n",
      "2/2 [==============================] - 0s 893us/step - loss: 15.6172 - mae: 15.6172\n",
      "Epoch 148/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 18.3065 - mae: 18.3065\n",
      "Epoch 149/500\n",
      "2/2 [==============================] - 0s 911us/step - loss: 8.1994 - mae: 8.1994\n",
      "Epoch 150/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.4964 - mae: 7.4964\n",
      "Epoch 151/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 18.3374 - mae: 18.3374\n",
      "Epoch 152/500\n",
      "2/2 [==============================] - 0s 968us/step - loss: 10.2895 - mae: 10.2895\n",
      "Epoch 153/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 29.6425 - mae: 29.6425\n",
      "Epoch 154/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.5556 - mae: 10.5556\n",
      "Epoch 155/500\n",
      "2/2 [==============================] - 0s 756us/step - loss: 15.4537 - mae: 15.4537\n",
      "Epoch 156/500\n",
      "2/2 [==============================] - 0s 915us/step - loss: 17.0174 - mae: 17.0174\n",
      "Epoch 157/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 32.8217 - mae: 32.8217\n",
      "Epoch 158/500\n",
      "2/2 [==============================] - 0s 797us/step - loss: 10.7038 - mae: 10.7038\n",
      "Epoch 159/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.9054 - mae: 8.9054\n",
      "Epoch 160/500\n",
      "2/2 [==============================] - 0s 807us/step - loss: 22.1321 - mae: 22.1321\n",
      "Epoch 161/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.7113 - mae: 11.7113\n",
      "Epoch 162/500\n",
      "2/2 [==============================] - 0s 806us/step - loss: 21.5734 - mae: 21.5734\n",
      "Epoch 163/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 19.2485 - mae: 19.2485\n",
      "Epoch 164/500\n",
      "2/2 [==============================] - 0s 990us/step - loss: 11.0156 - mae: 11.0156\n",
      "Epoch 165/500\n",
      "2/2 [==============================] - 0s 987us/step - loss: 9.6187 - mae: 9.6187\n",
      "Epoch 166/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 21.5908 - mae: 21.5908\n",
      "Epoch 167/500\n",
      "2/2 [==============================] - 0s 958us/step - loss: 26.2850 - mae: 26.2850\n",
      "Epoch 168/500\n",
      "2/2 [==============================] - 0s 945us/step - loss: 9.8525 - mae: 9.8525\n",
      "Epoch 169/500\n",
      "2/2 [==============================] - 0s 868us/step - loss: 22.5630 - mae: 22.5630\n",
      "Epoch 170/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.1499 - mae: 10.1499\n",
      "Epoch 171/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 18.0464 - mae: 18.0464\n",
      "Epoch 172/500\n",
      "2/2 [==============================] - 0s 970us/step - loss: 28.8377 - mae: 28.8377\n",
      "Epoch 173/500\n",
      "2/2 [==============================] - 0s 743us/step - loss: 16.5279 - mae: 16.5279\n",
      "Epoch 174/500\n",
      "2/2 [==============================] - 0s 942us/step - loss: 11.2115 - mae: 11.2115\n",
      "Epoch 175/500\n",
      "2/2 [==============================] - 0s 863us/step - loss: 27.5839 - mae: 27.5839\n",
      "Epoch 176/500\n",
      "2/2 [==============================] - 0s 808us/step - loss: 8.2680 - mae: 8.2680\n",
      "Epoch 177/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.2580 - mae: 9.2580\n",
      "Epoch 178/500\n",
      "2/2 [==============================] - 0s 885us/step - loss: 18.1440 - mae: 18.1440\n",
      "Epoch 179/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.5995 - mae: 10.5995\n",
      "Epoch 180/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 7.8992 - mae: 7.8992\n",
      "Epoch 181/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 17.4015 - mae: 17.4015\n",
      "Epoch 182/500\n",
      "2/2 [==============================] - 0s 919us/step - loss: 11.0089 - mae: 11.0089\n",
      "Epoch 183/500\n",
      "2/2 [==============================] - 0s 978us/step - loss: 11.7027 - mae: 11.7027\n",
      "Epoch 184/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 30.4062 - mae: 30.4062\n",
      "Epoch 185/500\n",
      "2/2 [==============================] - 0s 968us/step - loss: 7.5557 - mae: 7.5557\n",
      "Epoch 186/500\n",
      "2/2 [==============================] - 0s 992us/step - loss: 15.9905 - mae: 15.9905\n",
      "Epoch 187/500\n",
      "2/2 [==============================] - 0s 808us/step - loss: 8.5579 - mae: 8.5579\n",
      "Epoch 188/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 28.7339 - mae: 28.7339\n",
      "Epoch 189/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 13.1689 - mae: 13.1689\n",
      "Epoch 190/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 18.3101 - mae: 18.3101\n",
      "Epoch 191/500\n",
      "2/2 [==============================] - 0s 949us/step - loss: 13.7376 - mae: 13.7376\n",
      "Epoch 192/500\n",
      "2/2 [==============================] - 0s 993us/step - loss: 13.7104 - mae: 13.7104\n",
      "Epoch 193/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 28.5842 - mae: 28.5842\n",
      "Epoch 194/500\n",
      "2/2 [==============================] - 0s 935us/step - loss: 7.0707 - mae: 7.0707\n",
      "Epoch 195/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.0550 - mae: 7.0550\n",
      "Epoch 196/500\n",
      "2/2 [==============================] - 0s 977us/step - loss: 22.0067 - mae: 22.0067\n",
      "Epoch 197/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 20.8443 - mae: 20.8443\n",
      "Epoch 198/500\n",
      "2/2 [==============================] - 0s 822us/step - loss: 12.4713 - mae: 12.4713\n",
      "Epoch 199/500\n",
      "2/2 [==============================] - 0s 902us/step - loss: 17.9099 - mae: 17.9099\n",
      "Epoch 200/500\n",
      "2/2 [==============================] - 0s 751us/step - loss: 13.7494 - mae: 13.7494\n",
      "Epoch 201/500\n",
      "2/2 [==============================] - 0s 915us/step - loss: 5.4687 - mae: 5.4687\n",
      "Epoch 202/500\n",
      "2/2 [==============================] - 0s 849us/step - loss: 13.7006 - mae: 13.7006\n",
      "Epoch 203/500\n",
      "2/2 [==============================] - 0s 964us/step - loss: 9.4142 - mae: 9.4142\n",
      "Epoch 204/500\n",
      "2/2 [==============================] - 0s 951us/step - loss: 20.9796 - mae: 20.9796\n",
      "Epoch 205/500\n",
      "2/2 [==============================] - 0s 893us/step - loss: 9.5470 - mae: 9.5470\n",
      "Epoch 206/500\n",
      "2/2 [==============================] - 0s 923us/step - loss: 11.7256 - mae: 11.7256\n",
      "Epoch 207/500\n",
      "2/2 [==============================] - 0s 981us/step - loss: 14.3772 - mae: 14.3772\n",
      "Epoch 208/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 14.8579 - mae: 14.8579\n",
      "Epoch 209/500\n",
      "2/2 [==============================] - 0s 857us/step - loss: 14.9706 - mae: 14.9706\n",
      "Epoch 210/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 17.8998 - mae: 17.8998\n",
      "Epoch 211/500\n",
      "2/2 [==============================] - 0s 968us/step - loss: 9.8327 - mae: 9.8327\n",
      "Epoch 212/500\n",
      "2/2 [==============================] - 0s 957us/step - loss: 18.3352 - mae: 18.3352\n",
      "Epoch 213/500\n",
      "2/2 [==============================] - 0s 963us/step - loss: 15.0383 - mae: 15.0383\n",
      "Epoch 214/500\n",
      "2/2 [==============================] - 0s 802us/step - loss: 14.5874 - mae: 14.5874\n",
      "Epoch 215/500\n",
      "2/2 [==============================] - 0s 935us/step - loss: 23.3015 - mae: 23.3015\n",
      "Epoch 216/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 13.3613 - mae: 13.3613\n",
      "Epoch 217/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.8517 - mae: 9.8517\n",
      "Epoch 218/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.5451 - mae: 12.5451\n",
      "Epoch 219/500\n",
      "2/2 [==============================] - 0s 960us/step - loss: 4.9472 - mae: 4.9472\n",
      "Epoch 220/500\n",
      "2/2 [==============================] - 0s 973us/step - loss: 7.1129 - mae: 7.1129\n",
      "Epoch 221/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 35.4567 - mae: 35.4567\n",
      "Epoch 222/500\n",
      "2/2 [==============================] - 0s 926us/step - loss: 34.8634 - mae: 34.8634\n",
      "Epoch 223/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.9846 - mae: 7.9846\n",
      "Epoch 224/500\n",
      "2/2 [==============================] - 0s 868us/step - loss: 14.7003 - mae: 14.7003\n",
      "Epoch 225/500\n",
      "2/2 [==============================] - 0s 884us/step - loss: 16.7196 - mae: 16.7196\n",
      "Epoch 226/500\n",
      "2/2 [==============================] - 0s 983us/step - loss: 15.9329 - mae: 15.9329\n",
      "Epoch 227/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 16.1644 - mae: 16.1644\n",
      "Epoch 228/500\n",
      "2/2 [==============================] - 0s 954us/step - loss: 13.9324 - mae: 13.9324\n",
      "Epoch 229/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 18.0504 - mae: 18.0504\n",
      "Epoch 230/500\n",
      "2/2 [==============================] - 0s 773us/step - loss: 15.6120 - mae: 15.6120\n",
      "Epoch 231/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 21.2041 - mae: 21.2041\n",
      "Epoch 232/500\n",
      "2/2 [==============================] - 0s 992us/step - loss: 25.2732 - mae: 25.2732\n",
      "Epoch 233/500\n",
      "2/2 [==============================] - 0s 994us/step - loss: 16.3176 - mae: 16.3176\n",
      "Epoch 234/500\n",
      "2/2 [==============================] - 0s 839us/step - loss: 7.2729 - mae: 7.2729\n",
      "Epoch 235/500\n",
      "2/2 [==============================] - 0s 763us/step - loss: 16.9688 - mae: 16.9688\n",
      "Epoch 236/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.1225 - mae: 7.1225\n",
      "Epoch 237/500\n",
      "2/2 [==============================] - 0s 915us/step - loss: 9.2058 - mae: 9.2058\n",
      "Epoch 238/500\n",
      "2/2 [==============================] - 0s 983us/step - loss: 8.0961 - mae: 8.0961\n",
      "Epoch 239/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 17.0538 - mae: 17.0538\n",
      "Epoch 240/500\n",
      "2/2 [==============================] - 0s 912us/step - loss: 8.8627 - mae: 8.8627\n",
      "Epoch 241/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 13.1711 - mae: 13.1711\n",
      "Epoch 242/500\n",
      "2/2 [==============================] - 0s 888us/step - loss: 8.7886 - mae: 8.7886\n",
      "Epoch 243/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 18.8161 - mae: 18.8161\n",
      "Epoch 244/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 14.0531 - mae: 14.0531\n",
      "Epoch 245/500\n",
      "2/2 [==============================] - 0s 982us/step - loss: 14.6831 - mae: 14.6831\n",
      "Epoch 246/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 15.8045 - mae: 15.8045\n",
      "Epoch 247/500\n",
      "2/2 [==============================] - 0s 984us/step - loss: 17.6810 - mae: 17.6810\n",
      "Epoch 248/500\n",
      "2/2 [==============================] - 0s 968us/step - loss: 13.2367 - mae: 13.2367\n",
      "Epoch 249/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 14.5070 - mae: 14.5070\n",
      "Epoch 250/500\n",
      "2/2 [==============================] - 0s 965us/step - loss: 23.2322 - mae: 23.2322\n",
      "Epoch 251/500\n",
      "2/2 [==============================] - 0s 833us/step - loss: 9.3009 - mae: 9.3009\n",
      "Epoch 252/500\n",
      "2/2 [==============================] - 0s 924us/step - loss: 36.6569 - mae: 36.6569\n",
      "Epoch 253/500\n",
      "2/2 [==============================] - 0s 915us/step - loss: 21.8206 - mae: 21.8206\n",
      "Epoch 254/500\n",
      "2/2 [==============================] - 0s 726us/step - loss: 7.2792 - mae: 7.2792\n",
      "Epoch 255/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 24.7127 - mae: 24.7127\n",
      "Epoch 256/500\n",
      "2/2 [==============================] - 0s 985us/step - loss: 12.4220 - mae: 12.4220\n",
      "Epoch 257/500\n",
      "2/2 [==============================] - 0s 971us/step - loss: 10.5823 - mae: 10.5823\n",
      "Epoch 258/500\n",
      "2/2 [==============================] - 0s 777us/step - loss: 14.4883 - mae: 14.4883\n",
      "Epoch 259/500\n",
      "2/2 [==============================] - 0s 755us/step - loss: 8.6132 - mae: 8.6132\n",
      "Epoch 260/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 43.0580 - mae: 43.0580\n",
      "Epoch 261/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 18.4611 - mae: 18.4611\n",
      "Epoch 262/500\n",
      "2/2 [==============================] - 0s 907us/step - loss: 6.8820 - mae: 6.8820\n",
      "Epoch 263/500\n",
      "2/2 [==============================] - 0s 921us/step - loss: 13.7211 - mae: 13.7211\n",
      "Epoch 264/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 21.0154 - mae: 21.0154\n",
      "Epoch 265/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 19.3731 - mae: 19.3731\n",
      "Epoch 266/500\n",
      "2/2 [==============================] - 0s 869us/step - loss: 11.4735 - mae: 11.4735\n",
      "Epoch 267/500\n",
      "2/2 [==============================] - 0s 799us/step - loss: 7.5302 - mae: 7.5302\n",
      "Epoch 268/500\n",
      "2/2 [==============================] - 0s 955us/step - loss: 21.6453 - mae: 21.6453\n",
      "Epoch 269/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 33.1785 - mae: 33.1785\n",
      "Epoch 270/500\n",
      "2/2 [==============================] - 0s 945us/step - loss: 10.0833 - mae: 10.0833\n",
      "Epoch 271/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.1012 - mae: 12.1012\n",
      "Epoch 272/500\n",
      "2/2 [==============================] - 0s 898us/step - loss: 26.1372 - mae: 26.1372\n",
      "Epoch 273/500\n",
      "2/2 [==============================] - 0s 946us/step - loss: 12.1751 - mae: 12.1751\n",
      "Epoch 274/500\n",
      "2/2 [==============================] - 0s 884us/step - loss: 13.3272 - mae: 13.3272\n",
      "Epoch 275/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 29.3775 - mae: 29.3775\n",
      "Epoch 276/500\n",
      "2/2 [==============================] - 0s 797us/step - loss: 7.3329 - mae: 7.3329\n",
      "Epoch 277/500\n",
      "2/2 [==============================] - 0s 888us/step - loss: 31.1362 - mae: 31.1362\n",
      "Epoch 278/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.3015 - mae: 12.3015\n",
      "Epoch 279/500\n",
      "2/2 [==============================] - 0s 803us/step - loss: 16.4103 - mae: 16.4103\n",
      "Epoch 280/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 21.9118 - mae: 21.9118\n",
      "Epoch 281/500\n",
      "2/2 [==============================] - 0s 865us/step - loss: 22.1500 - mae: 22.1500\n",
      "Epoch 282/500\n",
      "2/2 [==============================] - 0s 833us/step - loss: 7.7429 - mae: 7.7429\n",
      "Epoch 283/500\n",
      "2/2 [==============================] - 0s 935us/step - loss: 8.1429 - mae: 8.1429\n",
      "Epoch 284/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 24.9435 - mae: 24.9435\n",
      "Epoch 285/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 13.6958 - mae: 13.6958\n",
      "Epoch 286/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 6.8926 - mae: 6.8926\n",
      "Epoch 287/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 24.5352 - mae: 24.5352\n",
      "Epoch 288/500\n",
      "2/2 [==============================] - 0s 959us/step - loss: 20.1721 - mae: 20.1721\n",
      "Epoch 289/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.9658 - mae: 11.9658\n",
      "Epoch 290/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 16.5391 - mae: 16.5391\n",
      "Epoch 291/500\n",
      "2/2 [==============================] - 0s 919us/step - loss: 16.8017 - mae: 16.8017\n",
      "Epoch 292/500\n",
      "2/2 [==============================] - 0s 942us/step - loss: 9.4642 - mae: 9.4642\n",
      "Epoch 293/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 15.2710 - mae: 15.2710\n",
      "Epoch 294/500\n",
      "2/2 [==============================] - 0s 912us/step - loss: 22.7179 - mae: 22.7179\n",
      "Epoch 295/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 17.9234 - mae: 17.9234\n",
      "Epoch 296/500\n",
      "2/2 [==============================] - 0s 933us/step - loss: 6.1743 - mae: 6.1743\n",
      "Epoch 297/500\n",
      "2/2 [==============================] - 0s 879us/step - loss: 10.9440 - mae: 10.9440\n",
      "Epoch 298/500\n",
      "2/2 [==============================] - 0s 835us/step - loss: 23.1530 - mae: 23.1530\n",
      "Epoch 299/500\n",
      "2/2 [==============================] - 0s 942us/step - loss: 17.7331 - mae: 17.7331\n",
      "Epoch 300/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 6.9824 - mae: 6.9824\n",
      "Epoch 301/500\n",
      "2/2 [==============================] - 0s 909us/step - loss: 25.1857 - mae: 25.1857\n",
      "Epoch 302/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.9025 - mae: 8.9025\n",
      "Epoch 303/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 17.7668 - mae: 17.7668\n",
      "Epoch 304/500\n",
      "2/2 [==============================] - 0s 992us/step - loss: 11.0002 - mae: 11.0002\n",
      "Epoch 305/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.9191 - mae: 12.9191\n",
      "Epoch 306/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.4033 - mae: 8.4033\n",
      "Epoch 307/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 13.6094 - mae: 13.6094\n",
      "Epoch 308/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.4404 - mae: 7.4404\n",
      "Epoch 309/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.4642 - mae: 9.4642\n",
      "Epoch 310/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.7099 - mae: 10.7099\n",
      "Epoch 311/500\n",
      "2/2 [==============================] - 0s 882us/step - loss: 13.2814 - mae: 13.2814\n",
      "Epoch 312/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 29.9763 - mae: 29.9763\n",
      "Epoch 313/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.6304 - mae: 7.6304\n",
      "Epoch 314/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.9106 - mae: 9.9106\n",
      "Epoch 315/500\n",
      "2/2 [==============================] - 0s 926us/step - loss: 23.7669 - mae: 23.7669\n",
      "Epoch 316/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 16.3937 - mae: 16.3937\n",
      "Epoch 317/500\n",
      "2/2 [==============================] - 0s 935us/step - loss: 21.0758 - mae: 21.0758\n",
      "Epoch 318/500\n",
      "2/2 [==============================] - 0s 754us/step - loss: 7.9367 - mae: 7.9367\n",
      "Epoch 319/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 17.9731 - mae: 17.9731\n",
      "Epoch 320/500\n",
      "2/2 [==============================] - 0s 978us/step - loss: 10.2376 - mae: 10.2376\n",
      "Epoch 321/500\n",
      "2/2 [==============================] - 0s 889us/step - loss: 8.3338 - mae: 8.3338\n",
      "Epoch 322/500\n",
      "2/2 [==============================] - 0s 993us/step - loss: 5.0621 - mae: 5.0621\n",
      "Epoch 323/500\n",
      "2/2 [==============================] - 0s 888us/step - loss: 23.5109 - mae: 23.5109\n",
      "Epoch 324/500\n",
      "2/2 [==============================] - 0s 944us/step - loss: 6.8309 - mae: 6.8309\n",
      "Epoch 325/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 16.3863 - mae: 16.3863\n",
      "Epoch 326/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.5019 - mae: 7.5019\n",
      "Epoch 327/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 20.0573 - mae: 20.0573\n",
      "Epoch 328/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.7661 - mae: 13.7661\n",
      "Epoch 329/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 16.8282 - mae: 16.8282\n",
      "Epoch 330/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.0514 - mae: 7.0514\n",
      "Epoch 331/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 21.4846 - mae: 21.4846\n",
      "Epoch 332/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.2880 - mae: 12.2880\n",
      "Epoch 333/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.8117 - mae: 11.8117\n",
      "Epoch 334/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.3600 - mae: 8.3600\n",
      "Epoch 335/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.4833 - mae: 12.4833\n",
      "Epoch 336/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 32.2171 - mae: 32.2171\n",
      "Epoch 337/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.4477 - mae: 10.4477\n",
      "Epoch 338/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 19.6832 - mae: 19.6832\n",
      "Epoch 339/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 35.0762 - mae: 35.0762\n",
      "Epoch 340/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.4193 - mae: 10.4193\n",
      "Epoch 341/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.7625 - mae: 9.7625\n",
      "Epoch 342/500\n",
      "2/2 [==============================] - 0s 991us/step - loss: 11.9500 - mae: 11.9500\n",
      "Epoch 343/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.3943 - mae: 9.3943\n",
      "Epoch 344/500\n",
      "2/2 [==============================] - 0s 760us/step - loss: 5.6071 - mae: 5.6071\n",
      "Epoch 345/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 37.4876 - mae: 37.4876\n",
      "Epoch 346/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 16.8830 - mae: 16.8830\n",
      "Epoch 347/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.8748 - mae: 12.8748\n",
      "Epoch 348/500\n",
      "2/2 [==============================] - 0s 932us/step - loss: 8.1960 - mae: 8.1960\n",
      "Epoch 349/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 13.5568 - mae: 13.5568\n",
      "Epoch 350/500\n",
      "2/2 [==============================] - 0s 986us/step - loss: 15.4354 - mae: 15.4354\n",
      "Epoch 351/500\n",
      "2/2 [==============================] - 0s 938us/step - loss: 32.9626 - mae: 32.9626\n",
      "Epoch 352/500\n",
      "2/2 [==============================] - 0s 844us/step - loss: 14.2040 - mae: 14.2040\n",
      "Epoch 353/500\n",
      "2/2 [==============================] - 0s 733us/step - loss: 15.9196 - mae: 15.9196\n",
      "Epoch 354/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 19.0878 - mae: 19.0878\n",
      "Epoch 355/500\n",
      "2/2 [==============================] - 0s 897us/step - loss: 34.1178 - mae: 34.1178\n",
      "Epoch 356/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.6798 - mae: 7.6798\n",
      "Epoch 357/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 25.2287 - mae: 25.2287\n",
      "Epoch 358/500\n",
      "2/2 [==============================] - 0s 966us/step - loss: 22.6759 - mae: 22.6759\n",
      "Epoch 359/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.8765 - mae: 8.8765\n",
      "Epoch 360/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 21.4709 - mae: 21.4709\n",
      "Epoch 361/500\n",
      "2/2 [==============================] - 0s 957us/step - loss: 20.6073 - mae: 20.6073\n",
      "Epoch 362/500\n",
      "2/2 [==============================] - 0s 860us/step - loss: 7.0611 - mae: 7.0611\n",
      "Epoch 363/500\n",
      "2/2 [==============================] - 0s 856us/step - loss: 25.8117 - mae: 25.8117\n",
      "Epoch 364/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 32.2248 - mae: 32.2248\n",
      "Epoch 365/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.0205 - mae: 10.0205\n",
      "Epoch 366/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.6722 - mae: 9.6722\n",
      "Epoch 367/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 30.4171 - mae: 30.4171\n",
      "Epoch 368/500\n",
      "2/2 [==============================] - 0s 850us/step - loss: 10.5020 - mae: 10.5020\n",
      "Epoch 369/500\n",
      "2/2 [==============================] - 0s 888us/step - loss: 14.9909 - mae: 14.9909\n",
      "Epoch 370/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 14.6580 - mae: 14.6580\n",
      "Epoch 371/500\n",
      "2/2 [==============================] - 0s 809us/step - loss: 23.3672 - mae: 23.3672\n",
      "Epoch 372/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 13.1025 - mae: 13.1025\n",
      "Epoch 373/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.2587 - mae: 9.2587\n",
      "Epoch 374/500\n",
      "2/2 [==============================] - 0s 944us/step - loss: 9.6648 - mae: 9.6648\n",
      "Epoch 375/500\n",
      "2/2 [==============================] - 0s 736us/step - loss: 13.0041 - mae: 13.0041\n",
      "Epoch 376/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 14.8863 - mae: 14.8863\n",
      "Epoch 377/500\n",
      "2/2 [==============================] - 0s 906us/step - loss: 14.7932 - mae: 14.7932\n",
      "Epoch 378/500\n",
      "2/2 [==============================] - 0s 955us/step - loss: 16.2751 - mae: 16.2751\n",
      "Epoch 379/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 20.8307 - mae: 20.8307\n",
      "Epoch 380/500\n",
      "2/2 [==============================] - 0s 977us/step - loss: 33.5318 - mae: 33.5318\n",
      "Epoch 381/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.2166 - mae: 8.2166\n",
      "Epoch 382/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 13.0960 - mae: 13.0960\n",
      "Epoch 383/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.3999 - mae: 8.3999\n",
      "Epoch 384/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.1283 - mae: 7.1283\n",
      "Epoch 385/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.9390 - mae: 10.9390\n",
      "Epoch 386/500\n",
      "2/2 [==============================] - 0s 848us/step - loss: 19.7654 - mae: 19.7654\n",
      "Epoch 387/500\n",
      "2/2 [==============================] - 0s 834us/step - loss: 24.8625 - mae: 24.8625\n",
      "Epoch 388/500\n",
      "2/2 [==============================] - 0s 782us/step - loss: 8.7422 - mae: 8.7422\n",
      "Epoch 389/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 5.9488 - mae: 5.9488\n",
      "Epoch 390/500\n",
      "2/2 [==============================] - 0s 935us/step - loss: 24.4401 - mae: 24.4401\n",
      "Epoch 391/500\n",
      "2/2 [==============================] - 0s 949us/step - loss: 5.9771 - mae: 5.9771\n",
      "Epoch 392/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 16.3250 - mae: 16.3250\n",
      "Epoch 393/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 6.0917 - mae: 6.0917\n",
      "Epoch 394/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.0963 - mae: 11.0963\n",
      "Epoch 395/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.9601 - mae: 14.9601\n",
      "Epoch 396/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.6462 - mae: 7.6462\n",
      "Epoch 397/500\n",
      "2/2 [==============================] - 0s 782us/step - loss: 8.7654 - mae: 8.7654\n",
      "Epoch 398/500\n",
      "2/2 [==============================] - 0s 920us/step - loss: 14.5992 - mae: 14.5992\n",
      "Epoch 399/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.3166 - mae: 11.3166\n",
      "Epoch 400/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 21.9080 - mae: 21.9080\n",
      "Epoch 401/500\n",
      "2/2 [==============================] - 0s 821us/step - loss: 14.8654 - mae: 14.8654\n",
      "Epoch 402/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.4970 - mae: 8.4970\n",
      "Epoch 403/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.3957 - mae: 10.3957\n",
      "Epoch 404/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.2556 - mae: 10.2556\n",
      "Epoch 405/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 6.3392 - mae: 6.3392\n",
      "Epoch 406/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 17.4602 - mae: 17.4602\n",
      "Epoch 407/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.4627 - mae: 11.4627\n",
      "Epoch 408/500\n",
      "2/2 [==============================] - 0s 964us/step - loss: 20.7294 - mae: 20.7294\n",
      "Epoch 409/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 31.3339 - mae: 31.3339\n",
      "Epoch 410/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.2542 - mae: 9.2542\n",
      "Epoch 411/500\n",
      "2/2 [==============================] - 0s 831us/step - loss: 14.8621 - mae: 14.8621\n",
      "Epoch 412/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 21.7182 - mae: 21.7182\n",
      "Epoch 413/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.6615 - mae: 12.6615\n",
      "Epoch 414/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 6.0687 - mae: 6.0687\n",
      "Epoch 415/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 13.2201 - mae: 13.2201\n",
      "Epoch 416/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 27.4244 - mae: 27.4244\n",
      "Epoch 417/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.6407 - mae: 10.6407\n",
      "Epoch 418/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.8230 - mae: 12.8230\n",
      "Epoch 419/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.8836 - mae: 15.8836\n",
      "Epoch 420/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 24.7510 - mae: 24.7510\n",
      "Epoch 421/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 17.3753 - mae: 17.3753\n",
      "Epoch 422/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.8241 - mae: 7.8241\n",
      "Epoch 423/500\n",
      "2/2 [==============================] - 0s 967us/step - loss: 25.3789 - mae: 25.3789\n",
      "Epoch 424/500\n",
      "2/2 [==============================] - 0s 924us/step - loss: 15.1031 - mae: 15.1031\n",
      "Epoch 425/500\n",
      "2/2 [==============================] - 0s 766us/step - loss: 7.1643 - mae: 7.1643\n",
      "Epoch 426/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 20.3318 - mae: 20.3318\n",
      "Epoch 427/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 6.3283 - mae: 6.3283\n",
      "Epoch 428/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.9962 - mae: 12.9962\n",
      "Epoch 429/500\n",
      "2/2 [==============================] - 0s 864us/step - loss: 10.7869 - mae: 10.7869\n",
      "Epoch 430/500\n",
      "2/2 [==============================] - 0s 985us/step - loss: 11.4007 - mae: 11.4007\n",
      "Epoch 431/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.6152 - mae: 10.6152\n",
      "Epoch 432/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.4582 - mae: 11.4582\n",
      "Epoch 433/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.3851 - mae: 11.3851\n",
      "Epoch 434/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 30.3986 - mae: 30.3986\n",
      "Epoch 435/500\n",
      "2/2 [==============================] - 0s 816us/step - loss: 10.5052 - mae: 10.5052\n",
      "Epoch 436/500\n",
      "2/2 [==============================] - 0s 930us/step - loss: 28.8810 - mae: 28.8810\n",
      "Epoch 437/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.5916 - mae: 8.5916\n",
      "Epoch 438/500\n",
      "2/2 [==============================] - 0s 885us/step - loss: 12.7378 - mae: 12.7378\n",
      "Epoch 439/500\n",
      "2/2 [==============================] - 0s 917us/step - loss: 33.6754 - mae: 33.6754\n",
      "Epoch 440/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 15.0962 - mae: 15.0962\n",
      "Epoch 441/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 17.4813 - mae: 17.4813\n",
      "Epoch 442/500\n",
      "2/2 [==============================] - 0s 840us/step - loss: 22.3049 - mae: 22.3049\n",
      "Epoch 443/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 23.5841 - mae: 23.5841\n",
      "Epoch 444/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.0008 - mae: 11.0008\n",
      "Epoch 445/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 14.9175 - mae: 14.9175\n",
      "Epoch 446/500\n",
      "2/2 [==============================] - 0s 850us/step - loss: 17.9979 - mae: 17.9979\n",
      "Epoch 447/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 5.4482 - mae: 5.4482\n",
      "Epoch 448/500\n",
      "2/2 [==============================] - 0s 900us/step - loss: 10.0527 - mae: 10.0527\n",
      "Epoch 449/500\n",
      "2/2 [==============================] - 0s 919us/step - loss: 14.0052 - mae: 14.0052\n",
      "Epoch 450/500\n",
      "2/2 [==============================] - 0s 967us/step - loss: 16.7782 - mae: 16.7782\n",
      "Epoch 451/500\n",
      "2/2 [==============================] - 0s 725us/step - loss: 14.2937 - mae: 14.2937\n",
      "Epoch 452/500\n",
      "2/2 [==============================] - 0s 902us/step - loss: 30.6193 - mae: 30.6193\n",
      "Epoch 453/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.6541 - mae: 7.6541\n",
      "Epoch 454/500\n",
      "2/2 [==============================] - 0s 796us/step - loss: 28.1428 - mae: 28.1428\n",
      "Epoch 455/500\n",
      "2/2 [==============================] - 0s 958us/step - loss: 8.0017 - mae: 8.0017\n",
      "Epoch 456/500\n",
      "2/2 [==============================] - 0s 879us/step - loss: 10.3933 - mae: 10.3933\n",
      "Epoch 457/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.0242 - mae: 15.0242\n",
      "Epoch 458/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 16.5653 - mae: 16.5653\n",
      "Epoch 459/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 26.8566 - mae: 26.8566\n",
      "Epoch 460/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.4852 - mae: 12.4852\n",
      "Epoch 461/500\n",
      "2/2 [==============================] - 0s 762us/step - loss: 12.4784 - mae: 12.4784\n",
      "Epoch 462/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.3186 - mae: 13.3186\n",
      "Epoch 463/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 29.5524 - mae: 29.5524\n",
      "Epoch 464/500\n",
      "2/2 [==============================] - 0s 892us/step - loss: 3.4664 - mae: 3.4664\n",
      "Epoch 465/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 15.2136 - mae: 15.2136\n",
      "Epoch 466/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 20.8327 - mae: 20.8327\n",
      "Epoch 467/500\n",
      "2/2 [==============================] - 0s 774us/step - loss: 30.5108 - mae: 30.5108\n",
      "Epoch 468/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.0597 - mae: 11.0597\n",
      "Epoch 469/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.8372 - mae: 12.8372\n",
      "Epoch 470/500\n",
      "2/2 [==============================] - 0s 914us/step - loss: 3.2398 - mae: 3.2398\n",
      "Epoch 471/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 16.6964 - mae: 16.6964\n",
      "Epoch 472/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 13.3883 - mae: 13.3883\n",
      "Epoch 473/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.2771 - mae: 15.2771\n",
      "Epoch 474/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.7448 - mae: 11.7448\n",
      "Epoch 475/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 16.4113 - mae: 16.4113\n",
      "Epoch 476/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 13.8785 - mae: 13.8785\n",
      "Epoch 477/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 30.6702 - mae: 30.6702\n",
      "Epoch 478/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.5880 - mae: 8.5880\n",
      "Epoch 479/500\n",
      "2/2 [==============================] - 0s 932us/step - loss: 10.7384 - mae: 10.7384\n",
      "Epoch 480/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 17.9051 - mae: 17.9051\n",
      "Epoch 481/500\n",
      "2/2 [==============================] - 0s 801us/step - loss: 15.8095 - mae: 15.8095\n",
      "Epoch 482/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 21.3054 - mae: 21.3054\n",
      "Epoch 483/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 25.3845 - mae: 25.3845\n",
      "Epoch 484/500\n",
      "2/2 [==============================] - 0s 945us/step - loss: 23.9815 - mae: 23.9815\n",
      "Epoch 485/500\n",
      "2/2 [==============================] - 0s 956us/step - loss: 5.7734 - mae: 5.7734\n",
      "Epoch 486/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 20.0010 - mae: 20.0010\n",
      "Epoch 487/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 14.0419 - mae: 14.0419\n",
      "Epoch 488/500\n",
      "2/2 [==============================] - 0s 861us/step - loss: 30.6088 - mae: 30.6088\n",
      "Epoch 489/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.9409 - mae: 11.9409\n",
      "Epoch 490/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.7352 - mae: 12.7352\n",
      "Epoch 491/500\n",
      "2/2 [==============================] - 0s 886us/step - loss: 23.6139 - mae: 23.6139\n",
      "Epoch 492/500\n",
      "2/2 [==============================] - 0s 953us/step - loss: 20.5365 - mae: 20.5365\n",
      "Epoch 493/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.9942 - mae: 4.9942\n",
      "Epoch 494/500\n",
      "2/2 [==============================] - 0s 812us/step - loss: 12.7986 - mae: 12.7986\n",
      "Epoch 495/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 13.3772 - mae: 13.3772\n",
      "Epoch 496/500\n",
      "2/2 [==============================] - 0s 925us/step - loss: 12.6727 - mae: 12.6727\n",
      "Epoch 497/500\n",
      "2/2 [==============================] - 0s 950us/step - loss: 17.6192 - mae: 17.6192\n",
      "Epoch 498/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 23.5629 - mae: 23.5629\n",
      "Epoch 499/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.3755 - mae: 9.3755\n",
      "Epoch 500/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 14.6316 - mae: 14.6316\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5a701b9cd0>"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "# Make and plot some predictions\n",
    "y_preds_3 = model_3.predict(X_test)\n",
    "plot_predictions(predictions=y_preds_3)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "# Calculate model_3 evaluation metrics\n",
    "mae_3 = mae(y_test, y_preds_3)\n",
    "mse_3 = mse(y_test, y_preds_3)\n",
    "mae_3, mse_3"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=68.71362>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4808.0283>)"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The model is probably overfitting! Meaning it has learned the training data too well and it's not able to generalize on data it hasn't seen before"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Comparing the results of our experiments"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "# Compare our models results using a pandas DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "model_results = [[\"model_1\", mae_1.numpy(), mse_1.numpy()],\n",
    "                 [\"model_2\", mae_2.numpy(), mse_2.numpy()],\n",
    "                 [\"model_3\", mae_3.numpy(), mse_3.numpy()]]\n",
    "\n",
    "all_results = pd.DataFrame(model_results, columns=[\"model\", \"mae\", \"mse\"])\n",
    "\n",
    "all_results"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     model        mae          mse\n",
       "0  model_1  18.745327   353.573395\n",
       "1  model_2   3.196964    13.070300\n",
       "2  model_3  68.713623  4808.028320"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model_1</td>\n",
       "      <td>18.745327</td>\n",
       "      <td>353.573395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>model_2</td>\n",
       "      <td>3.196964</td>\n",
       "      <td>13.070300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>model_3</td>\n",
       "      <td>68.713623</td>\n",
       "      <td>4808.028320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Looks like `model_2` performed the best"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "model_2.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              multiple                  20        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              multiple                  11        \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tracking your experiments\n",
    "\n",
    "A really good practice is to track the results of the experiments.\n",
    "It can be tedious if we are running a lot of experiments.\n",
    "\n",
    "Luckily there are tools to help us.\n",
    "**Resources:**\n",
    "* TensorBoard - a component of TensorFlow library to help track modeling experiments.\n",
    "* Weights & Biases - a tool of tracking all kind of machine learning experiment. Plugs straight into TensorBoard"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save a model\n",
    "\n",
    "Saving a model allows to use them outside wherever they are trained.\n",
    "\n",
    "There are two main formats we can save models to:\n",
    "1. SavedModel format\n",
    "2. HDF5 format"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "# Save model in SavedModel format\n",
    "# model_2.save(\"best_model_SavedModel_format\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From /home/lpianta/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py:1813: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: best_model_SavedModel_format/assets\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "# Save model in HDF5 format\n",
    "# model_2.save(\"best_model_HDF5_format.h5\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load a saved model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "# Load the SavedModel format\n",
    "loaded_SaveModel_format = tf.keras.models.load_model(\"best_model_SavedModel_format\")\n",
    "loaded_SaveModel_format.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              multiple                  20        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              multiple                  11        \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "# Compare model_2 predictions with SavedModel format model predictions\n",
    "model_2_preds = model_2.predict(X_test)\n",
    "loaded_SaveModel_format_preds = loaded_SaveModel_format.predict(X_test)\n",
    "model_2_preds == loaded_SaveModel_format_preds"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]])"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "# Load the .h5 model\n",
    "loaded_h5_model = tf.keras.models.load_model(\"best_model_HDF5_format.h5\")\n",
    "loaded_h5_model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              multiple                  20        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              multiple                  11        \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "# Check if architecture is the same as model_2\n",
    "model_2.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              multiple                  20        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              multiple                  11        \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "# Compare predictions\n",
    "model_2_preds = model_2.predict(X_test)\n",
    "loaded_h5_model_preds = loaded_h5_model.predict(X_test)\n",
    "model_2_preds == loaded_h5_model_preds"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]])"
      ]
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## A larger example"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "# Import required libraries\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "# Read insurance csv from github\n",
    "insurance = pd.read_csv(\"https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv\")\n",
    "insurance"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      age     sex     bmi  children smoker     region      charges\n",
       "0      19  female  27.900         0    yes  southwest  16884.92400\n",
       "1      18    male  33.770         1     no  southeast   1725.55230\n",
       "2      28    male  33.000         3     no  southeast   4449.46200\n",
       "3      33    male  22.705         0     no  northwest  21984.47061\n",
       "4      32    male  28.880         0     no  northwest   3866.85520\n",
       "...   ...     ...     ...       ...    ...        ...          ...\n",
       "1333   50    male  30.970         3     no  northwest  10600.54830\n",
       "1334   18  female  31.920         0     no  northeast   2205.98080\n",
       "1335   18  female  36.850         0     no  southeast   1629.83350\n",
       "1336   21  female  25.800         0     no  southwest   2007.94500\n",
       "1337   61  female  29.070         0    yes  northwest  29141.36030\n",
       "\n",
       "[1338 rows x 7 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>50</td>\n",
       "      <td>male</td>\n",
       "      <td>30.970</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>10600.54830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>31.920</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northeast</td>\n",
       "      <td>2205.98080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>36.850</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1629.83350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>21</td>\n",
       "      <td>female</td>\n",
       "      <td>25.800</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southwest</td>\n",
       "      <td>2007.94500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>61</td>\n",
       "      <td>female</td>\n",
       "      <td>29.070</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>northwest</td>\n",
       "      <td>29141.36030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows Ã 7 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "# Check dtype of columns\n",
    "insurance.dtypes"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "age           int64\n",
       "sex          object\n",
       "bmi         float64\n",
       "children      int64\n",
       "smoker       object\n",
       "region       object\n",
       "charges     float64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "# One-hot encode object columns\n",
    "insurance_onehot = pd.get_dummies(insurance)\n",
    "insurance_onehot"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      age     bmi  children      charges  sex_female  sex_male  smoker_no  \\\n",
       "0      19  27.900         0  16884.92400           1         0          0   \n",
       "1      18  33.770         1   1725.55230           0         1          1   \n",
       "2      28  33.000         3   4449.46200           0         1          1   \n",
       "3      33  22.705         0  21984.47061           0         1          1   \n",
       "4      32  28.880         0   3866.85520           0         1          1   \n",
       "...   ...     ...       ...          ...         ...       ...        ...   \n",
       "1333   50  30.970         3  10600.54830           0         1          1   \n",
       "1334   18  31.920         0   2205.98080           1         0          1   \n",
       "1335   18  36.850         0   1629.83350           1         0          1   \n",
       "1336   21  25.800         0   2007.94500           1         0          1   \n",
       "1337   61  29.070         0  29141.36030           1         0          0   \n",
       "\n",
       "      smoker_yes  region_northeast  region_northwest  region_southeast  \\\n",
       "0              1                 0                 0                 0   \n",
       "1              0                 0                 0                 1   \n",
       "2              0                 0                 0                 1   \n",
       "3              0                 0                 1                 0   \n",
       "4              0                 0                 1                 0   \n",
       "...          ...               ...               ...               ...   \n",
       "1333           0                 0                 1                 0   \n",
       "1334           0                 1                 0                 0   \n",
       "1335           0                 0                 0                 1   \n",
       "1336           0                 0                 0                 0   \n",
       "1337           1                 0                 1                 0   \n",
       "\n",
       "      region_southwest  \n",
       "0                    1  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    0  \n",
       "4                    0  \n",
       "...                ...  \n",
       "1333                 0  \n",
       "1334                 0  \n",
       "1335                 0  \n",
       "1336                 1  \n",
       "1337                 0  \n",
       "\n",
       "[1338 rows x 12 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>charges</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>smoker_no</th>\n",
       "      <th>smoker_yes</th>\n",
       "      <th>region_northeast</th>\n",
       "      <th>region_northwest</th>\n",
       "      <th>region_southeast</th>\n",
       "      <th>region_southwest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>16884.92400</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>1725.55230</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>4449.46200</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>21984.47061</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>3866.85520</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>50</td>\n",
       "      <td>30.970</td>\n",
       "      <td>3</td>\n",
       "      <td>10600.54830</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>18</td>\n",
       "      <td>31.920</td>\n",
       "      <td>0</td>\n",
       "      <td>2205.98080</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>18</td>\n",
       "      <td>36.850</td>\n",
       "      <td>0</td>\n",
       "      <td>1629.83350</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>21</td>\n",
       "      <td>25.800</td>\n",
       "      <td>0</td>\n",
       "      <td>2007.94500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>61</td>\n",
       "      <td>29.070</td>\n",
       "      <td>0</td>\n",
       "      <td>29141.36030</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows Ã 12 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "# Create X and y values (features and labels)\n",
    "X = insurance_onehot.drop(\"charges\", axis=1)\n",
    "y = insurance_onehot[\"charges\"]\n",
    "X, y"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(      age     bmi  children  sex_female  sex_male  smoker_no  smoker_yes  \\\n",
       " 0      19  27.900         0           1         0          0           1   \n",
       " 1      18  33.770         1           0         1          1           0   \n",
       " 2      28  33.000         3           0         1          1           0   \n",
       " 3      33  22.705         0           0         1          1           0   \n",
       " 4      32  28.880         0           0         1          1           0   \n",
       " ...   ...     ...       ...         ...       ...        ...         ...   \n",
       " 1333   50  30.970         3           0         1          1           0   \n",
       " 1334   18  31.920         0           1         0          1           0   \n",
       " 1335   18  36.850         0           1         0          1           0   \n",
       " 1336   21  25.800         0           1         0          1           0   \n",
       " 1337   61  29.070         0           1         0          0           1   \n",
       " \n",
       "       region_northeast  region_northwest  region_southeast  region_southwest  \n",
       " 0                    0                 0                 0                 1  \n",
       " 1                    0                 0                 1                 0  \n",
       " 2                    0                 0                 1                 0  \n",
       " 3                    0                 1                 0                 0  \n",
       " 4                    0                 1                 0                 0  \n",
       " ...                ...               ...               ...               ...  \n",
       " 1333                 0                 1                 0                 0  \n",
       " 1334                 1                 0                 0                 0  \n",
       " 1335                 0                 0                 1                 0  \n",
       " 1336                 0                 0                 0                 1  \n",
       " 1337                 0                 1                 0                 0  \n",
       " \n",
       " [1338 rows x 11 columns],\n",
       " 0       16884.92400\n",
       " 1        1725.55230\n",
       " 2        4449.46200\n",
       " 3       21984.47061\n",
       " 4        3866.85520\n",
       "            ...     \n",
       " 1333    10600.54830\n",
       " 1334     2205.98080\n",
       " 1335     1629.83350\n",
       " 1336     2007.94500\n",
       " 1337    29141.36030\n",
       " Name: charges, Length: 1338, dtype: float64)"
      ]
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "source": [
    "# Create training and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "source": [
    "# Build a neural network\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1, Create the model\n",
    "insurance_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "insurance_model.compile(loss=tf.keras.losses.mae,\n",
    "              optimizer=tf.keras.optimizers.SGD(),\n",
    "              metrics=[\"mae\"])\n",
    "\n",
    "# Fit the model\n",
    "insurance_model.fit(X_train, y_train, epochs=100)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_12 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8637.1006 - mae: 8637.1006\n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7886.7759 - mae: 7886.7759\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7558.1470 - mae: 7558.1470\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7792.0220 - mae: 7792.0220\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7748.3887 - mae: 7748.3887\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7595.3945 - mae: 7595.3945\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7589.9849 - mae: 7589.9849\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7698.5581 - mae: 7698.5581\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7496.7788 - mae: 7496.7788\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7493.1743 - mae: 7493.1743\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7769.7310 - mae: 7769.7310\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7706.9048 - mae: 7706.9048\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7687.7227 - mae: 7687.7227\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7689.8999 - mae: 7689.8999\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7393.5317 - mae: 7393.5317\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7780.6978 - mae: 7780.6978\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7578.5107 - mae: 7578.5107\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7750.8350 - mae: 7750.8350\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7739.2144 - mae: 7739.2144\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7875.0654 - mae: 7875.0654\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7466.6768 - mae: 7466.6768\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7941.2329 - mae: 7941.2329\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7640.2725 - mae: 7640.2725\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7539.2671 - mae: 7539.2671\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7619.9653 - mae: 7619.9653\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7644.1709 - mae: 7644.1709\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7709.0376 - mae: 7709.0376\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7366.8662 - mae: 7366.8662\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7444.3159 - mae: 7444.3159\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7616.4077 - mae: 7616.4077\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7686.3853 - mae: 7686.3853\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7548.0986 - mae: 7548.0986\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7501.5542 - mae: 7501.5542\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7363.4160 - mae: 7363.4160\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7295.4468 - mae: 7295.4468\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7569.8804 - mae: 7569.8804\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7548.2002 - mae: 7548.2002\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7424.3979 - mae: 7424.3979\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7529.7734 - mae: 7529.7734\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7467.3242 - mae: 7467.3242\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7635.9292 - mae: 7635.9292\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7536.8398 - mae: 7536.8398\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7616.5850 - mae: 7616.5850\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7439.4941 - mae: 7439.4941\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7538.0146 - mae: 7538.0146\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7415.1470 - mae: 7415.1470\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7420.6929 - mae: 7420.6929\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7509.9839 - mae: 7509.9839\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7541.1133 - mae: 7541.1133\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7467.8643 - mae: 7467.8643\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7389.3560 - mae: 7389.3560\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7499.7754 - mae: 7499.7754\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7523.9282 - mae: 7523.9282\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7243.3120 - mae: 7243.3120\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7429.5874 - mae: 7429.5874\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7313.3999 - mae: 7313.3999\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7526.3887 - mae: 7526.3887\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7542.2666 - mae: 7542.2666\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7576.9282 - mae: 7576.9282\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7546.4048 - mae: 7546.4048\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7351.2271 - mae: 7351.2271\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7302.1436 - mae: 7302.1436\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7393.0874 - mae: 7393.0874\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7442.2881 - mae: 7442.2881\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7492.6787 - mae: 7492.6787\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7561.9165 - mae: 7561.9165\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7340.5137 - mae: 7340.5137\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7496.0850 - mae: 7496.0850\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7617.0303 - mae: 7617.0303\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7641.1948 - mae: 7641.1948\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7084.2739 - mae: 7084.2739\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7240.4912 - mae: 7240.4912\n",
      "Epoch 73/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7283.4893 - mae: 7283.4893\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7335.5073 - mae: 7335.5073\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7275.6392 - mae: 7275.6392\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7313.1855 - mae: 7313.1855\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7485.7578 - mae: 7485.7578\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7352.2798 - mae: 7352.2798\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7520.5708 - mae: 7520.5708\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7279.3784 - mae: 7279.3784\n",
      "Epoch 81/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7273.8477 - mae: 7273.8477\n",
      "Epoch 82/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7176.5215 - mae: 7176.5215\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7425.6289 - mae: 7425.6289\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7403.1294 - mae: 7403.1294\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7356.0083 - mae: 7356.0083\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7484.7271 - mae: 7484.7271\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7217.6079 - mae: 7217.6079\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7261.0000 - mae: 7261.0000\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7134.1558 - mae: 7134.1558\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7083.4351 - mae: 7083.4351\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7254.1782 - mae: 7254.1782\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7268.7451 - mae: 7268.7451\n",
      "Epoch 93/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7470.5215 - mae: 7470.5215\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7210.9541 - mae: 7210.9541\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7395.6797 - mae: 7395.6797\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7328.0884 - mae: 7328.0884\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7230.4375 - mae: 7230.4375\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7261.3940 - mae: 7261.3940\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7342.5684 - mae: 7342.5684\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7106.1704 - mae: 7106.1704\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5970f863d0>"
      ]
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "source": [
    "# Evaluate on the test data\n",
    "insurance_model.evaluate(X_test, y_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "9/9 [==============================] - 0s 858us/step - loss: 7023.3267 - mae: 7023.3267\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[7023.32666015625, 7023.32666015625]"
      ]
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "y_train.median(),y_train.mean()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(9575.4421, 13346.089736364485)"
      ]
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Given the mean and the median, our model isn't performing too well. We need to improve it!\n",
    "\n",
    "We'll run 2 experiments:\n",
    "1. Add an extra layer with more hidden units (we had to change the optimizer too because the model was too large to perform with SGD optimizer)\n",
    "2. Same as above but train for longer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "# Adding an extra layer\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "insurance_model_2 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(100),\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "insurance_model_2.compile(loss=tf.keras.losses.mae,\n",
    "                          optimizer=tf.keras.optimizers.Adam(),\n",
    "                          metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "insurance_model_2.fit(X_train, y_train, epochs=100, verbose=1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_17 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 13273.1602 - mae: 13273.1602\n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 13104.4287 - mae: 13104.4287\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 12749.5400 - mae: 12749.5400\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 12055.7500 - mae: 12055.7500\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 10905.8154 - mae: 10905.8154\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 9457.7188 - mae: 9457.7188\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8147.6533 - mae: 8147.6533\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7528.8398 - mae: 7528.8398\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7429.1528 - mae: 7429.1528\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7409.0806 - mae: 7409.0806\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7390.8042 - mae: 7390.8042\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7368.9170 - mae: 7368.9170\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7348.5195 - mae: 7348.5195\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7326.4893 - mae: 7326.4893\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7307.5811 - mae: 7307.5811\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7285.7734 - mae: 7285.7734\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7265.7100 - mae: 7265.7100\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7242.5503 - mae: 7242.5503\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7220.5068 - mae: 7220.5068\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7197.1973 - mae: 7197.1973\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7179.0195 - mae: 7179.0195\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7151.2104 - mae: 7151.2104\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7126.4639 - mae: 7126.4639\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7101.9194 - mae: 7101.9194\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7084.3379 - mae: 7084.3379\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7052.3291 - mae: 7052.3291\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7024.3511 - mae: 7024.3511\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6996.6963 - mae: 6996.6963\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6969.0107 - mae: 6969.0107\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6942.1899 - mae: 6942.1899\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6911.7290 - mae: 6911.7290\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6884.0205 - mae: 6884.0205\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6853.4648 - mae: 6853.4648\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6823.0674 - mae: 6823.0674\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6789.6865 - mae: 6789.6865\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6755.7646 - mae: 6755.7646\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6720.2036 - mae: 6720.2036\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6689.7163 - mae: 6689.7163\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6652.4619 - mae: 6652.4619\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6618.1011 - mae: 6618.1011\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6585.8643 - mae: 6585.8643\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6559.4956 - mae: 6559.4956\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6530.0444 - mae: 6530.0444\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6506.8071 - mae: 6506.8071\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6493.5718 - mae: 6493.5718\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6475.9263 - mae: 6475.9263\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6458.8979 - mae: 6458.8979\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6445.1494 - mae: 6445.1494\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6430.9639 - mae: 6430.9639\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6417.7515 - mae: 6417.7515\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6403.2754 - mae: 6403.2754\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6392.4141 - mae: 6392.4141\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6378.7456 - mae: 6378.7456\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6364.9131 - mae: 6364.9131\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6351.5273 - mae: 6351.5273\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6337.6606 - mae: 6337.6606\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6324.8369 - mae: 6324.8369\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6310.1948 - mae: 6310.1948\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6295.6035 - mae: 6295.6035\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6284.8701 - mae: 6284.8701\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6265.6411 - mae: 6265.6411\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6253.0112 - mae: 6253.0112\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6234.9292 - mae: 6234.9292\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6218.0435 - mae: 6218.0435\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6201.1899 - mae: 6201.1899\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6183.9595 - mae: 6183.9595\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6171.2993 - mae: 6171.2993\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6148.8403 - mae: 6148.8403\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6132.5991 - mae: 6132.5991\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6112.3848 - mae: 6112.3848\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6092.7207 - mae: 6092.7207\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6073.7422 - mae: 6073.7422\n",
      "Epoch 73/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6059.4883 - mae: 6059.4883\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6031.3857 - mae: 6031.3857\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6010.3350 - mae: 6010.3350\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5995.2188 - mae: 5995.2188\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5963.0723 - mae: 5963.0723\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5940.0610 - mae: 5940.0610\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5915.1064 - mae: 5915.1064\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5887.9995 - mae: 5887.9995\n",
      "Epoch 81/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5861.6992 - mae: 5861.6992\n",
      "Epoch 82/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5834.3081 - mae: 5834.3081\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5805.8242 - mae: 5805.8242\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5772.3237 - mae: 5772.3237\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5745.1519 - mae: 5745.1519\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5711.3491 - mae: 5711.3491\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5674.5220 - mae: 5674.5220\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5639.4932 - mae: 5639.4932\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5600.6665 - mae: 5600.6665\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5559.4336 - mae: 5559.4336\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5523.6196 - mae: 5523.6196\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5474.1255 - mae: 5474.1255\n",
      "Epoch 93/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5432.2661 - mae: 5432.2661\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5386.0537 - mae: 5386.0537\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5333.1812 - mae: 5333.1812\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5288.8169 - mae: 5288.8169\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5234.6797 - mae: 5234.6797\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5170.9375 - mae: 5170.9375\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5112.9458 - mae: 5112.9458\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5060.0879 - mae: 5060.0879\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5998a2a5e0>"
      ]
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "source": [
    "# Evaluate model_2\n",
    "insurance_model_2.evaluate(X_test, y_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "9/9 [==============================] - 0s 1ms/step - loss: 4924.5107 - mae: 4924.5107\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[4924.5107421875, 4924.5107421875]"
      ]
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "source": [
    "# Build model 3\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "insurance_model_3 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(100),\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "insurance_model_3.compile(loss=tf.keras.losses.mae,\n",
    "                          optimizer=tf.keras.optimizers.Adam(),\n",
    "                          metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "history = insurance_model_3.fit(X_train, y_train, epochs=200)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/200\n",
      "WARNING:tensorflow:Layer dense_23 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 13273.1602 - mae: 13273.1602\n",
      "Epoch 2/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 13104.4287 - mae: 13104.4287\n",
      "Epoch 3/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 12749.5400 - mae: 12749.5400\n",
      "Epoch 4/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 12055.7500 - mae: 12055.7500\n",
      "Epoch 5/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 10905.8154 - mae: 10905.8154\n",
      "Epoch 6/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 9457.7188 - mae: 9457.7188\n",
      "Epoch 7/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 8147.6533 - mae: 8147.6533\n",
      "Epoch 8/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7528.8398 - mae: 7528.8398\n",
      "Epoch 9/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7429.1528 - mae: 7429.1528\n",
      "Epoch 10/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7409.0806 - mae: 7409.0806\n",
      "Epoch 11/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7390.8042 - mae: 7390.8042\n",
      "Epoch 12/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7368.9170 - mae: 7368.9170\n",
      "Epoch 13/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7348.5195 - mae: 7348.5195\n",
      "Epoch 14/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7326.4893 - mae: 7326.4893\n",
      "Epoch 15/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7307.5811 - mae: 7307.5811\n",
      "Epoch 16/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7285.7734 - mae: 7285.7734\n",
      "Epoch 17/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7265.7100 - mae: 7265.7100\n",
      "Epoch 18/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7242.5503 - mae: 7242.5503\n",
      "Epoch 19/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7220.5068 - mae: 7220.5068\n",
      "Epoch 20/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7197.1973 - mae: 7197.1973\n",
      "Epoch 21/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7179.0195 - mae: 7179.0195\n",
      "Epoch 22/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7151.2104 - mae: 7151.2104\n",
      "Epoch 23/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7126.4639 - mae: 7126.4639\n",
      "Epoch 24/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7101.9194 - mae: 7101.9194\n",
      "Epoch 25/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7084.3379 - mae: 7084.3379\n",
      "Epoch 26/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7052.3291 - mae: 7052.3291\n",
      "Epoch 27/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7024.3511 - mae: 7024.3511\n",
      "Epoch 28/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6996.6963 - mae: 6996.6963\n",
      "Epoch 29/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6969.0107 - mae: 6969.0107\n",
      "Epoch 30/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6942.1899 - mae: 6942.1899\n",
      "Epoch 31/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6911.7290 - mae: 6911.7290\n",
      "Epoch 32/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6884.0205 - mae: 6884.0205\n",
      "Epoch 33/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6853.4648 - mae: 6853.4648\n",
      "Epoch 34/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6823.0674 - mae: 6823.0674\n",
      "Epoch 35/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6789.6865 - mae: 6789.6865\n",
      "Epoch 36/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6755.7646 - mae: 6755.7646\n",
      "Epoch 37/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6720.2036 - mae: 6720.2036\n",
      "Epoch 38/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6689.7163 - mae: 6689.7163\n",
      "Epoch 39/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6652.4619 - mae: 6652.4619\n",
      "Epoch 40/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6618.1011 - mae: 6618.1011\n",
      "Epoch 41/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6585.8643 - mae: 6585.8643\n",
      "Epoch 42/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6559.4956 - mae: 6559.4956\n",
      "Epoch 43/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6530.0444 - mae: 6530.0444\n",
      "Epoch 44/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6506.8071 - mae: 6506.8071\n",
      "Epoch 45/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6493.5718 - mae: 6493.5718\n",
      "Epoch 46/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6475.9263 - mae: 6475.9263\n",
      "Epoch 47/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6458.8979 - mae: 6458.8979\n",
      "Epoch 48/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6445.1494 - mae: 6445.1494\n",
      "Epoch 49/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6430.9639 - mae: 6430.9639\n",
      "Epoch 50/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6417.7515 - mae: 6417.7515\n",
      "Epoch 51/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6403.2754 - mae: 6403.2754\n",
      "Epoch 52/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6392.4141 - mae: 6392.4141\n",
      "Epoch 53/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6378.7456 - mae: 6378.7456\n",
      "Epoch 54/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6364.9131 - mae: 6364.9131\n",
      "Epoch 55/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6351.5273 - mae: 6351.5273\n",
      "Epoch 56/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6337.6606 - mae: 6337.6606\n",
      "Epoch 57/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6324.8369 - mae: 6324.8369\n",
      "Epoch 58/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6310.1948 - mae: 6310.1948\n",
      "Epoch 59/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6295.6035 - mae: 6295.6035\n",
      "Epoch 60/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6284.8701 - mae: 6284.8701\n",
      "Epoch 61/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6265.6411 - mae: 6265.6411\n",
      "Epoch 62/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6253.0112 - mae: 6253.0112\n",
      "Epoch 63/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6234.9292 - mae: 6234.9292\n",
      "Epoch 64/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6218.0435 - mae: 6218.0435\n",
      "Epoch 65/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6201.1899 - mae: 6201.1899\n",
      "Epoch 66/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6183.9595 - mae: 6183.9595\n",
      "Epoch 67/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6171.2993 - mae: 6171.2993\n",
      "Epoch 68/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6148.8403 - mae: 6148.8403\n",
      "Epoch 69/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6132.5991 - mae: 6132.5991\n",
      "Epoch 70/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6112.3848 - mae: 6112.3848\n",
      "Epoch 71/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6092.7207 - mae: 6092.7207\n",
      "Epoch 72/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6073.7422 - mae: 6073.7422\n",
      "Epoch 73/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6059.4883 - mae: 6059.4883\n",
      "Epoch 74/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6031.3857 - mae: 6031.3857\n",
      "Epoch 75/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6010.3350 - mae: 6010.3350\n",
      "Epoch 76/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5995.2188 - mae: 5995.2188\n",
      "Epoch 77/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5963.0723 - mae: 5963.0723\n",
      "Epoch 78/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5940.0610 - mae: 5940.0610\n",
      "Epoch 79/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5915.1064 - mae: 5915.1064\n",
      "Epoch 80/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5887.9995 - mae: 5887.9995\n",
      "Epoch 81/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5861.6992 - mae: 5861.6992\n",
      "Epoch 82/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5834.3081 - mae: 5834.3081\n",
      "Epoch 83/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5805.8242 - mae: 5805.8242\n",
      "Epoch 84/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5772.3237 - mae: 5772.3237\n",
      "Epoch 85/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5745.1519 - mae: 5745.1519\n",
      "Epoch 86/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5711.3491 - mae: 5711.3491\n",
      "Epoch 87/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5674.5220 - mae: 5674.5220\n",
      "Epoch 88/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5639.4932 - mae: 5639.4932\n",
      "Epoch 89/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5600.6665 - mae: 5600.6665\n",
      "Epoch 90/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5559.4336 - mae: 5559.4336\n",
      "Epoch 91/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5523.6196 - mae: 5523.6196\n",
      "Epoch 92/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5474.1255 - mae: 5474.1255\n",
      "Epoch 93/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5432.2661 - mae: 5432.2661\n",
      "Epoch 94/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5386.0537 - mae: 5386.0537\n",
      "Epoch 95/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5333.1812 - mae: 5333.1812\n",
      "Epoch 96/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5288.8169 - mae: 5288.8169\n",
      "Epoch 97/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5234.6797 - mae: 5234.6797\n",
      "Epoch 98/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5170.9375 - mae: 5170.9375\n",
      "Epoch 99/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5112.9458 - mae: 5112.9458\n",
      "Epoch 100/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5060.0879 - mae: 5060.0879\n",
      "Epoch 101/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 4987.7427 - mae: 4987.7427\n",
      "Epoch 102/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 4915.4482 - mae: 4915.4482\n",
      "Epoch 103/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4847.4873 - mae: 4847.4873\n",
      "Epoch 104/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4768.1816 - mae: 4768.1816\n",
      "Epoch 105/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4683.4653 - mae: 4683.4653\n",
      "Epoch 106/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 4601.2080 - mae: 4601.2080\n",
      "Epoch 107/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 4513.4644 - mae: 4513.4644\n",
      "Epoch 108/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 4423.5952 - mae: 4423.5952\n",
      "Epoch 109/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4339.2173 - mae: 4339.2173\n",
      "Epoch 110/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4255.7876 - mae: 4255.7876\n",
      "Epoch 111/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4174.8784 - mae: 4174.8784\n",
      "Epoch 112/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 4101.4253 - mae: 4101.4253\n",
      "Epoch 113/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4031.7214 - mae: 4031.7214\n",
      "Epoch 114/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3986.9104 - mae: 3986.9104\n",
      "Epoch 115/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3944.5930 - mae: 3944.5930\n",
      "Epoch 116/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3918.6152 - mae: 3918.6152\n",
      "Epoch 117/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3896.7400 - mae: 3896.7400\n",
      "Epoch 118/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3872.1240 - mae: 3872.1240\n",
      "Epoch 119/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3851.9661 - mae: 3851.9661\n",
      "Epoch 120/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3835.4458 - mae: 3835.4458\n",
      "Epoch 121/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3829.4529 - mae: 3829.4529\n",
      "Epoch 122/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3822.5405 - mae: 3822.5405\n",
      "Epoch 123/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3814.8994 - mae: 3814.8994\n",
      "Epoch 124/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3806.8062 - mae: 3806.8062\n",
      "Epoch 125/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3795.5430 - mae: 3795.5430\n",
      "Epoch 126/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3807.1846 - mae: 3807.1846\n",
      "Epoch 127/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3797.8484 - mae: 3797.8484\n",
      "Epoch 128/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3791.7207 - mae: 3791.7207\n",
      "Epoch 129/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3802.8040 - mae: 3802.8040\n",
      "Epoch 130/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3789.7971 - mae: 3789.7971\n",
      "Epoch 131/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3781.4006 - mae: 3781.4006\n",
      "Epoch 132/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3774.9460 - mae: 3774.9460\n",
      "Epoch 133/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3770.7563 - mae: 3770.7563\n",
      "Epoch 134/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3769.5461 - mae: 3769.5461\n",
      "Epoch 135/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3767.2349 - mae: 3767.2349\n",
      "Epoch 136/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3766.0596 - mae: 3766.0596\n",
      "Epoch 137/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3775.8564 - mae: 3775.8564\n",
      "Epoch 138/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3783.4236 - mae: 3783.4236\n",
      "Epoch 139/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3761.3589 - mae: 3761.3589\n",
      "Epoch 140/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3762.6267 - mae: 3762.6267\n",
      "Epoch 141/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3763.7036 - mae: 3763.7036\n",
      "Epoch 142/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3765.6414 - mae: 3765.6414\n",
      "Epoch 143/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3755.0132 - mae: 3755.0132\n",
      "Epoch 144/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3750.5750 - mae: 3750.5750\n",
      "Epoch 145/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3751.1663 - mae: 3751.1663\n",
      "Epoch 146/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3756.9319 - mae: 3756.9319\n",
      "Epoch 147/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3751.6331 - mae: 3751.6331\n",
      "Epoch 148/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3756.2720 - mae: 3756.2720\n",
      "Epoch 149/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3743.5862 - mae: 3743.5862\n",
      "Epoch 150/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3738.7124 - mae: 3738.7124\n",
      "Epoch 151/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3741.1475 - mae: 3741.1475\n",
      "Epoch 152/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3742.1655 - mae: 3742.1655\n",
      "Epoch 153/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3743.0066 - mae: 3743.0066\n",
      "Epoch 154/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3737.0344 - mae: 3737.0344\n",
      "Epoch 155/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3737.9746 - mae: 3737.9746\n",
      "Epoch 156/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3736.7349 - mae: 3736.7349\n",
      "Epoch 157/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3732.5815 - mae: 3732.5815\n",
      "Epoch 158/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3729.4280 - mae: 3729.4280\n",
      "Epoch 159/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3728.5608 - mae: 3728.5608\n",
      "Epoch 160/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3733.9951 - mae: 3733.9951\n",
      "Epoch 161/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3728.1079 - mae: 3728.1079\n",
      "Epoch 162/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3725.3667 - mae: 3725.3667\n",
      "Epoch 163/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3722.9509 - mae: 3722.9509\n",
      "Epoch 164/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3727.0618 - mae: 3727.0618\n",
      "Epoch 165/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3717.6621 - mae: 3717.6621\n",
      "Epoch 166/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3720.3694 - mae: 3720.3694\n",
      "Epoch 167/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3720.2910 - mae: 3720.2910\n",
      "Epoch 168/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3717.2761 - mae: 3717.2761\n",
      "Epoch 169/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3713.5608 - mae: 3713.5608\n",
      "Epoch 170/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3708.0085 - mae: 3708.0085\n",
      "Epoch 171/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3707.6399 - mae: 3707.6399\n",
      "Epoch 172/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3709.0312 - mae: 3709.0312\n",
      "Epoch 173/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3705.1497 - mae: 3705.1497\n",
      "Epoch 174/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3709.5410 - mae: 3709.5410\n",
      "Epoch 175/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3710.9673 - mae: 3710.9673\n",
      "Epoch 176/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3706.6682 - mae: 3706.6682\n",
      "Epoch 177/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3698.9155 - mae: 3698.9155\n",
      "Epoch 178/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3695.3813 - mae: 3695.3813\n",
      "Epoch 179/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3706.8618 - mae: 3706.8618\n",
      "Epoch 180/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3709.3879 - mae: 3709.3879\n",
      "Epoch 181/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3695.9612 - mae: 3695.9612\n",
      "Epoch 182/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3693.4849 - mae: 3693.4849\n",
      "Epoch 183/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3691.5908 - mae: 3691.5908\n",
      "Epoch 184/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3697.9917 - mae: 3697.9917\n",
      "Epoch 185/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3692.3057 - mae: 3692.3057\n",
      "Epoch 186/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3695.7458 - mae: 3695.7458\n",
      "Epoch 187/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3688.8062 - mae: 3688.8062\n",
      "Epoch 188/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3693.3765 - mae: 3693.3765\n",
      "Epoch 189/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3684.3000 - mae: 3684.3000\n",
      "Epoch 190/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3682.4170 - mae: 3682.4170\n",
      "Epoch 191/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3701.8770 - mae: 3701.8770\n",
      "Epoch 192/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3685.1748 - mae: 3685.1748\n",
      "Epoch 193/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3674.1245 - mae: 3674.1245\n",
      "Epoch 194/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3674.9353 - mae: 3674.9353\n",
      "Epoch 195/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3672.9138 - mae: 3672.9138\n",
      "Epoch 196/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3681.3555 - mae: 3681.3555\n",
      "Epoch 197/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3666.5703 - mae: 3666.5703\n",
      "Epoch 198/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3672.4155 - mae: 3672.4155\n",
      "Epoch 199/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3680.3149 - mae: 3680.3149\n",
      "Epoch 200/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3668.1565 - mae: 3668.1565\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "source": [
    "# Evaluate model 3\n",
    "insurance_model_3.evaluate(X_test, y_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "9/9 [==============================] - 0s 1ms/step - loss: 3494.5327 - mae: 3494.5327\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[3494.53271484375, 3494.53271484375]"
      ]
     },
     "metadata": {},
     "execution_count": 78
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "source": [
    "# Plot history (also known as loss curve or training curve)\n",
    "pd.DataFrame(history.history).plot()\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epochs\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'epochs')"
      ]
     },
     "metadata": {},
     "execution_count": 79
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing data (normalization and standardization)"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "beaeedd000c0f311d8dd0b4801970756eb4932ef7c2f76491d7ecc71e583b6a9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('tensorflow': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}